{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResearchProject(Batch Normalization).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G208cjNPsdP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvu7ivtuse9Y",
        "colab_type": "text"
      },
      "source": [
        "# **Building A Movie Recommandation System With Pytorch(Batch Normalization)**\n",
        "In this project, we are trying to predict the ratings that a user will give to an unseen movie, based on the ratings he gave to other movies. We will use the movielens dataset.The Main folder, which is ml-100k contains informations about 100 000 movies. We will use AutoEncoders to create our recommandation system. Let's start by importing the required libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OaoIf9R_Bf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AutoEncoders\n",
        "\n",
        "# Importing the libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9kM0xA6ncI6",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d0fafe71-cde3-435c-a487-1920292a9953"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-63e6dcec-c29e-4a38-8548-c030e6c35ac8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-63e6dcec-c29e-4a38-8548-c030e6c35ac8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving u1.base to u1.base\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZqjzECzoDeV",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0f35d30b-7c3c-4dab-8b24-8113ce638179"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-445b5eb3-55ff-41f5-9e57-d5175a3d081d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-445b5eb3-55ff-41f5-9e57-d5175a3d081d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving u1.test to u1.test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L82ZWs_i6Kq",
        "colab_type": "text"
      },
      "source": [
        "# Batch Size 200\n",
        "\n",
        "\n",
        "*   TRAINING LOSS: 0.0714\n",
        "*   TEST LOSS: 0.0796\n",
        "*   RMSE LOSS:0.2821\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YF9WpDRuZBZz",
        "colab": {}
      },
      "source": [
        "training = ['user_id', 'movie_id', 'rating', 'timestamp' ] #Create each column\n",
        "test = ['user_id', 'movie_id', 'rating', 'timestamp' ]     #Create each column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ibD8DQ6GZBZ7",
        "colab": {}
      },
      "source": [
        "# Preparing the training set and the test set \n",
        "training_set = pd.read_csv('u1.base', names=training, delimiter = '\\t') # Read the file\n",
        "test_set = pd.read_csv('u1.test', names=test, delimiter = '\\t') #Read the file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LwkZejB_ZBZ_",
        "colab": {}
      },
      "source": [
        "#Drop 'timestamp' column\n",
        "training_set= training_set.drop([\"timestamp\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8_2vgZ5wZBaF",
        "colab": {}
      },
      "source": [
        "#Drop 'timestamp' column\n",
        "test_set= test_set.drop([\"timestamp\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9oa1iefEZBaI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dafbf329-2352-4b61-9ec8-010d503893a6"
      },
      "source": [
        "# Visualizing the first elements of the training_set\n",
        "training_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  movie_id  rating\n",
              "0        1         1       5\n",
              "1        1         2       3\n",
              "2        1         3       4\n",
              "3        1         4       3\n",
              "4        1         5       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YbTWeULHZBaN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3994594b-42d1-42cb-8984-5f5f1cfb0faf"
      },
      "source": [
        "training_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PB0-QL6aZBaT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9eae97f2-3fa6-4323-90a7-e779aa220fe1"
      },
      "source": [
        "test_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OVo2f6olZBaY",
        "colab": {}
      },
      "source": [
        "# Converting the training and test sets into numpy arrays\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dMo1nEarZBab",
        "colab": {}
      },
      "source": [
        "# Getting the number of users and movies\n",
        "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kOzxn7YsZBaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "acbd08e9-d189-4807-e6b5-e7c042bd077c"
      },
      "source": [
        "print(\"Number of users: {}\".format(nb_users))\n",
        "print(\"Number of movies: {}\".format(nb_movies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users: 943\n",
            "Number of movies: 1682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JoL2L9nEZBal",
        "colab": {}
      },
      "source": [
        "def convert(data):\n",
        "    # Initializing an empty list that will take the list of ratings given by a specific user\n",
        "    new_data = []\n",
        "    # Looping over all the users\n",
        "    for id_users in range(1, nb_users + 1):\n",
        "        # We get the id of the movies rated by the current user\n",
        "        id_movies = data[:, 1][data[:, 0] == id_users]\n",
        "        # We get the id of the ratings given by the current_user\n",
        "        id_ratings = data[:, 2][data[:, 0] == id_users]\n",
        "        # \n",
        "        ratings = np.zeros(nb_movies)\n",
        "        # For movies rated by the current user, we replace 0 with the rating\n",
        "        # The first element of ratings is at index 0. However, id_movies start at index 1.\n",
        "        # Therefore, ratings[id_movies - 1] will correspond to the location of the movie we're considering\n",
        "        ratings[id_movies - 1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uuc0MoBeZBao",
        "colab": {}
      },
      "source": [
        "# Applying the convert function to the training and test set.\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3UNBoV0UZBas",
        "colab": {}
      },
      "source": [
        "# Convert the data into Torch tensors\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCbbELuyud34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size  = 200\n",
        "\n",
        "''' Dataset Class'''\n",
        "class DatasetR(Dataset):\n",
        "    \"\"\"Youtube-VOS dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, training_set, nb_users, transform=None):\n",
        "        super(DatasetR, self).__init__()\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.training_set = training_set\n",
        "        self.nb_users = nb_users\n",
        "    def __len__(self):\n",
        "        return self.nb_users\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #print(idx)\n",
        "        sample = self.training_set[idx]\n",
        "\n",
        "\n",
        "        #sample = torch.Tensor(sample)\n",
        "\n",
        "\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8VM5oJJaHiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SAE(nn.Module):\n",
        "    # Initializing the class\n",
        "    def __init__(self, ):\n",
        "        # making the class get all the functions from the parent class nn.Module\n",
        "        super(SAE, self).__init__()\n",
        "        # Creating the first encoding layer. The number of input corresponds to the number of movies\n",
        "        #  Decide to encode it into 20 outputs\n",
        "        self.fc1 = nn.Linear(nb_movies, 20)\n",
        "        # Batch Normalization.\n",
        "        self.bn1 = nn.BatchNorm1d(20)\n",
        "        # Creating the second encoding layer. From 20 inputs to 10 outputs\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "        # Batch Normalization.\n",
        "        self.bn2 = nn.BatchNorm1d(10)\n",
        "        # Creating the first decoding layer. From 10 inputs to 20 outputs\n",
        "        self.fc3 = nn.Linear(10, 20)\n",
        "        # Batch Normalization\n",
        "        self.bn3 = nn.BatchNorm1d(20)\n",
        "        # Creating the second hidden layer. From 20 inputs to nb_movies outputs\n",
        "        self.fc4 = nn.Linear(20, nb_movies)\n",
        "        # Creating the activation fucntion which will fire up specific neurons \n",
        "        self.activation = nn.Sigmoid()\n",
        "        \n",
        "        # Creating the function for forward propagation\n",
        "    def forward(self, x):\n",
        "        # x = self.do1(self.bn1(self.activation(self.fc1(x))))\n",
        "        # x = self.do2(self.bn2(self.activation(self.fc2(x))))\n",
        "        # x = self.do3(self.bn3(self.activation(self.fc3(x))))\n",
        "\n",
        "        x = self.bn1(self.activation(self.fc1(x)))\n",
        "        x = self.bn2(self.activation(self.fc2(x)))\n",
        "        x = self.bn3(self.activation(self.fc3(x)))\n",
        "        # With autoencoder, we don't need an activation function for the last decoding part\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "          \n",
        "    def predict(self, x): # x: visible nodes\n",
        "        x = self.forward(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx-9-Azza36n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #Creating an instance of our SAE class\n",
        "sae = SAE()\n",
        "\n",
        "dataset = DatasetR(training_set = training_set, nb_users = nb_users)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "\n",
        "datasetTest = DatasetR(training_set = test_set, nb_users = nb_users)\n",
        "test_loader = torch.utils.data.DataLoader(datasetTest, batch_size = batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " #Defining a criterion which specifies the metric to minimize. In this case, we want to minimize the MSE (Mean Squared Error)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Defining the algorithm used to minimize the loss function. In this case, we'll use RMSprop\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYmH11gZbkki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e10925b-0eed-4cdf-fc2b-471415b7458c"
      },
      "source": [
        "# Setting the number of epochs\n",
        "\n",
        "losses = []\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "nb_epoch = 200\n",
        "\n",
        "# Iterating over each epoch\n",
        "\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "\n",
        "    #sae.train()\n",
        "\n",
        "    # Initializing the train_loss which will be updated\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    # Initializing a counter\n",
        "\n",
        "    s = 0.\n",
        "\n",
        "    # Iterating over each user\n",
        "\n",
        "    #for id_user in range(nb_users):\n",
        "\n",
        "    for batch_idx, (sample) in enumerate(train_loader):\n",
        "\n",
        "        # The input corresponds to the ratings given by the current user for each movie\n",
        "\n",
        "        input = Variable(sample)\n",
        "\n",
        "        target = input.clone()\n",
        "\n",
        "        # We don't consider movies NOT rated by the current user. So we specify a conditional statement\n",
        "\n",
        "        if torch.sum(target.data > 0) > 0:\n",
        "\n",
        "            # We use our SAE to get the output from the \n",
        "\n",
        "            #print('input:  '+ str(input.shape))\n",
        "\n",
        "            output = sae(input)\n",
        "\n",
        "            #print(output.shape)\n",
        "\n",
        "            target.require_grad = False\n",
        "\n",
        "            output[target == 0] = 0\n",
        "\n",
        "            # Defining our loss function, comparing the output with the target\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "\n",
        "            # Computing the gradients necessary to adjust the weights\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Updating the train_loss\n",
        "\n",
        "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
        "\n",
        "            s += 1.\n",
        "\n",
        "            # Updating the weights of the neural network\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "    epoch_loss = train_loss / len(train_loader)\n",
        "    losses.append(epoch_loss)  \n",
        "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
        "time_end = time.time()\n",
        "print('Stacked-Autoencoder(SAE) Training Time : ' +str(round((time_end-time_start)/60,0))+' Minutes. ')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss: tensor(0.2623)\n",
            "epoch: 2 loss: tensor(0.2606)\n",
            "epoch: 3 loss: tensor(0.2590)\n",
            "epoch: 4 loss: tensor(0.2564)\n",
            "epoch: 5 loss: tensor(0.2547)\n",
            "epoch: 6 loss: tensor(0.2541)\n",
            "epoch: 7 loss: tensor(0.2533)\n",
            "epoch: 8 loss: tensor(0.2520)\n",
            "epoch: 9 loss: tensor(0.2507)\n",
            "epoch: 10 loss: tensor(0.2477)\n",
            "epoch: 11 loss: tensor(0.2466)\n",
            "epoch: 12 loss: tensor(0.2427)\n",
            "epoch: 13 loss: tensor(0.2393)\n",
            "epoch: 14 loss: tensor(0.2340)\n",
            "epoch: 15 loss: tensor(0.2289)\n",
            "epoch: 16 loss: tensor(0.2219)\n",
            "epoch: 17 loss: tensor(0.2148)\n",
            "epoch: 18 loss: tensor(0.2051)\n",
            "epoch: 19 loss: tensor(0.1974)\n",
            "epoch: 20 loss: tensor(0.1881)\n",
            "epoch: 21 loss: tensor(0.1792)\n",
            "epoch: 22 loss: tensor(0.1706)\n",
            "epoch: 23 loss: tensor(0.1627)\n",
            "epoch: 24 loss: tensor(0.1560)\n",
            "epoch: 25 loss: tensor(0.1498)\n",
            "epoch: 26 loss: tensor(0.1440)\n",
            "epoch: 27 loss: tensor(0.1389)\n",
            "epoch: 28 loss: tensor(0.1355)\n",
            "epoch: 29 loss: tensor(0.1319)\n",
            "epoch: 30 loss: tensor(0.1276)\n",
            "epoch: 31 loss: tensor(0.1244)\n",
            "epoch: 32 loss: tensor(0.1217)\n",
            "epoch: 33 loss: tensor(0.1191)\n",
            "epoch: 34 loss: tensor(0.1168)\n",
            "epoch: 35 loss: tensor(0.1140)\n",
            "epoch: 36 loss: tensor(0.1117)\n",
            "epoch: 37 loss: tensor(0.1087)\n",
            "epoch: 38 loss: tensor(0.1077)\n",
            "epoch: 39 loss: tensor(0.1056)\n",
            "epoch: 40 loss: tensor(0.1046)\n",
            "epoch: 41 loss: tensor(0.1027)\n",
            "epoch: 42 loss: tensor(0.1013)\n",
            "epoch: 43 loss: tensor(0.1002)\n",
            "epoch: 44 loss: tensor(0.0996)\n",
            "epoch: 45 loss: tensor(0.0972)\n",
            "epoch: 46 loss: tensor(0.0968)\n",
            "epoch: 47 loss: tensor(0.0961)\n",
            "epoch: 48 loss: tensor(0.0957)\n",
            "epoch: 49 loss: tensor(0.0951)\n",
            "epoch: 50 loss: tensor(0.0925)\n",
            "epoch: 51 loss: tensor(0.0919)\n",
            "epoch: 52 loss: tensor(0.0910)\n",
            "epoch: 53 loss: tensor(0.0908)\n",
            "epoch: 54 loss: tensor(0.0910)\n",
            "epoch: 55 loss: tensor(0.0890)\n",
            "epoch: 56 loss: tensor(0.0899)\n",
            "epoch: 57 loss: tensor(0.0878)\n",
            "epoch: 58 loss: tensor(0.0880)\n",
            "epoch: 59 loss: tensor(0.0863)\n",
            "epoch: 60 loss: tensor(0.0858)\n",
            "epoch: 61 loss: tensor(0.0848)\n",
            "epoch: 62 loss: tensor(0.0862)\n",
            "epoch: 63 loss: tensor(0.0848)\n",
            "epoch: 64 loss: tensor(0.0841)\n",
            "epoch: 65 loss: tensor(0.0851)\n",
            "epoch: 66 loss: tensor(0.0843)\n",
            "epoch: 67 loss: tensor(0.0835)\n",
            "epoch: 68 loss: tensor(0.0826)\n",
            "epoch: 69 loss: tensor(0.0824)\n",
            "epoch: 70 loss: tensor(0.0824)\n",
            "epoch: 71 loss: tensor(0.0825)\n",
            "epoch: 72 loss: tensor(0.0825)\n",
            "epoch: 73 loss: tensor(0.0821)\n",
            "epoch: 74 loss: tensor(0.0820)\n",
            "epoch: 75 loss: tensor(0.0826)\n",
            "epoch: 76 loss: tensor(0.0818)\n",
            "epoch: 77 loss: tensor(0.0808)\n",
            "epoch: 78 loss: tensor(0.0824)\n",
            "epoch: 79 loss: tensor(0.0810)\n",
            "epoch: 80 loss: tensor(0.0821)\n",
            "epoch: 81 loss: tensor(0.0803)\n",
            "epoch: 82 loss: tensor(0.0802)\n",
            "epoch: 83 loss: tensor(0.0799)\n",
            "epoch: 84 loss: tensor(0.0794)\n",
            "epoch: 85 loss: tensor(0.0797)\n",
            "epoch: 86 loss: tensor(0.0789)\n",
            "epoch: 87 loss: tensor(0.0791)\n",
            "epoch: 88 loss: tensor(0.0791)\n",
            "epoch: 89 loss: tensor(0.0785)\n",
            "epoch: 90 loss: tensor(0.0788)\n",
            "epoch: 91 loss: tensor(0.0783)\n",
            "epoch: 92 loss: tensor(0.0792)\n",
            "epoch: 93 loss: tensor(0.0790)\n",
            "epoch: 94 loss: tensor(0.0779)\n",
            "epoch: 95 loss: tensor(0.0777)\n",
            "epoch: 96 loss: tensor(0.0776)\n",
            "epoch: 97 loss: tensor(0.0772)\n",
            "epoch: 98 loss: tensor(0.0774)\n",
            "epoch: 99 loss: tensor(0.0767)\n",
            "epoch: 100 loss: tensor(0.0764)\n",
            "epoch: 101 loss: tensor(0.0768)\n",
            "epoch: 102 loss: tensor(0.0766)\n",
            "epoch: 103 loss: tensor(0.0766)\n",
            "epoch: 104 loss: tensor(0.0777)\n",
            "epoch: 105 loss: tensor(0.0770)\n",
            "epoch: 106 loss: tensor(0.0768)\n",
            "epoch: 107 loss: tensor(0.0773)\n",
            "epoch: 108 loss: tensor(0.0754)\n",
            "epoch: 109 loss: tensor(0.0754)\n",
            "epoch: 110 loss: tensor(0.0758)\n",
            "epoch: 111 loss: tensor(0.0757)\n",
            "epoch: 112 loss: tensor(0.0754)\n",
            "epoch: 113 loss: tensor(0.0749)\n",
            "epoch: 114 loss: tensor(0.0756)\n",
            "epoch: 115 loss: tensor(0.0765)\n",
            "epoch: 116 loss: tensor(0.0760)\n",
            "epoch: 117 loss: tensor(0.0763)\n",
            "epoch: 118 loss: tensor(0.0750)\n",
            "epoch: 119 loss: tensor(0.0746)\n",
            "epoch: 120 loss: tensor(0.0741)\n",
            "epoch: 121 loss: tensor(0.0743)\n",
            "epoch: 122 loss: tensor(0.0755)\n",
            "epoch: 123 loss: tensor(0.0751)\n",
            "epoch: 124 loss: tensor(0.0747)\n",
            "epoch: 125 loss: tensor(0.0751)\n",
            "epoch: 126 loss: tensor(0.0759)\n",
            "epoch: 127 loss: tensor(0.0754)\n",
            "epoch: 128 loss: tensor(0.0745)\n",
            "epoch: 129 loss: tensor(0.0737)\n",
            "epoch: 130 loss: tensor(0.0738)\n",
            "epoch: 131 loss: tensor(0.0733)\n",
            "epoch: 132 loss: tensor(0.0731)\n",
            "epoch: 133 loss: tensor(0.0726)\n",
            "epoch: 134 loss: tensor(0.0732)\n",
            "epoch: 135 loss: tensor(0.0737)\n",
            "epoch: 136 loss: tensor(0.0744)\n",
            "epoch: 137 loss: tensor(0.0757)\n",
            "epoch: 138 loss: tensor(0.0752)\n",
            "epoch: 139 loss: tensor(0.0743)\n",
            "epoch: 140 loss: tensor(0.0733)\n",
            "epoch: 141 loss: tensor(0.0730)\n",
            "epoch: 142 loss: tensor(0.0725)\n",
            "epoch: 143 loss: tensor(0.0722)\n",
            "epoch: 144 loss: tensor(0.0719)\n",
            "epoch: 145 loss: tensor(0.0730)\n",
            "epoch: 146 loss: tensor(0.0732)\n",
            "epoch: 147 loss: tensor(0.0743)\n",
            "epoch: 148 loss: tensor(0.0737)\n",
            "epoch: 149 loss: tensor(0.0736)\n",
            "epoch: 150 loss: tensor(0.0734)\n",
            "epoch: 151 loss: tensor(0.0727)\n",
            "epoch: 152 loss: tensor(0.0718)\n",
            "epoch: 153 loss: tensor(0.0719)\n",
            "epoch: 154 loss: tensor(0.0718)\n",
            "epoch: 155 loss: tensor(0.0719)\n",
            "epoch: 156 loss: tensor(0.0725)\n",
            "epoch: 157 loss: tensor(0.0723)\n",
            "epoch: 158 loss: tensor(0.0737)\n",
            "epoch: 159 loss: tensor(0.0735)\n",
            "epoch: 160 loss: tensor(0.0736)\n",
            "epoch: 161 loss: tensor(0.0729)\n",
            "epoch: 162 loss: tensor(0.0718)\n",
            "epoch: 163 loss: tensor(0.0722)\n",
            "epoch: 164 loss: tensor(0.0723)\n",
            "epoch: 165 loss: tensor(0.0719)\n",
            "epoch: 166 loss: tensor(0.0716)\n",
            "epoch: 167 loss: tensor(0.0721)\n",
            "epoch: 168 loss: tensor(0.0722)\n",
            "epoch: 169 loss: tensor(0.0722)\n",
            "epoch: 170 loss: tensor(0.0727)\n",
            "epoch: 171 loss: tensor(0.0726)\n",
            "epoch: 172 loss: tensor(0.0720)\n",
            "epoch: 173 loss: tensor(0.0709)\n",
            "epoch: 174 loss: tensor(0.0715)\n",
            "epoch: 175 loss: tensor(0.0719)\n",
            "epoch: 176 loss: tensor(0.0714)\n",
            "epoch: 177 loss: tensor(0.0715)\n",
            "epoch: 178 loss: tensor(0.0714)\n",
            "epoch: 179 loss: tensor(0.0725)\n",
            "epoch: 180 loss: tensor(0.0727)\n",
            "epoch: 181 loss: tensor(0.0720)\n",
            "epoch: 182 loss: tensor(0.0719)\n",
            "epoch: 183 loss: tensor(0.0705)\n",
            "epoch: 184 loss: tensor(0.0708)\n",
            "epoch: 185 loss: tensor(0.0710)\n",
            "epoch: 186 loss: tensor(0.0711)\n",
            "epoch: 187 loss: tensor(0.0711)\n",
            "epoch: 188 loss: tensor(0.0708)\n",
            "epoch: 189 loss: tensor(0.0716)\n",
            "epoch: 190 loss: tensor(0.0723)\n",
            "epoch: 191 loss: tensor(0.0719)\n",
            "epoch: 192 loss: tensor(0.0714)\n",
            "epoch: 193 loss: tensor(0.0708)\n",
            "epoch: 194 loss: tensor(0.0711)\n",
            "epoch: 195 loss: tensor(0.0703)\n",
            "epoch: 196 loss: tensor(0.0715)\n",
            "epoch: 197 loss: tensor(0.0707)\n",
            "epoch: 198 loss: tensor(0.0715)\n",
            "epoch: 199 loss: tensor(0.0714)\n",
            "epoch: 200 loss: tensor(0.0714)\n",
            "Stacked-Autoencoder(SAE) Training Time : 1.0 Minutes. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRLFVb7x1F79",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7e074751-af75-44af-f500-6fa9380b66c1"
      },
      "source": [
        "epochs = range(1,201)\n",
        "plt.plot(epochs, losses, 'g', label='batch size = 200 ') # 'g' = color green\n",
        "plt.title('Batch Normalization- epoch = 200')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8ly1CyN1Od0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25f32e76-83ca-41e0-de6b-0c6192f1c1b2"
      },
      "source": [
        "with torch.no_grad():\n",
        "  sae.eval()\n",
        "  test_loss = 0\n",
        "  s = 0.\n",
        "  for input1,target1 in zip(train_loader,test_loader):\n",
        "      input = Variable(input1)\n",
        "      target = Variable(target1)\n",
        "      if torch.sum(target.data > 0) > 0:\n",
        "          output = sae(input)\n",
        "          target.require_grad = False\n",
        "          output[(target == 0)] = 0\n",
        "          loss = criterion(output, target)\n",
        "          mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "          test_loss += np.sqrt(loss.data*mean_corrector)\n",
        "          s += 1.\n",
        "  print('test_loss: '+str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss: tensor(0.0796)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO5zWvqxGrCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TI01_6XF5a7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import sqrt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDDia2UdE3gU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23a68a1f-bb8e-45b8-fe12-1abb61962ba2"
      },
      "source": [
        "RMSE = sqrt(0.0796)\n",
        "\n",
        "RMSE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2821347195933177"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTLLK812Fybb",
        "colab_type": "text"
      },
      "source": [
        "# Batch size 500\n",
        "\n",
        "*   TRAINING LOSS: 0.0583\n",
        "*   TEST LOSS: 0.0619\n",
        "*   RMSE LOSS:0.2487\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLit7sr0F9DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i9WW0gYtF9y8",
        "colab": {}
      },
      "source": [
        "training = ['user_id', 'movie_id', 'rating', 'timestamp' ] #Create each column\n",
        "test = ['user_id', 'movie_id', 'rating', 'timestamp' ]     #Create each column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0nmCpQl4F9zA",
        "colab": {}
      },
      "source": [
        "# Preparing the training set and the test set \n",
        "training_set = pd.read_csv('u1.base', names=training, delimiter = '\\t') # Read the file\n",
        "test_set = pd.read_csv('u1.test', names=test, delimiter = '\\t') #Read the file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l0yf7LciF9zD",
        "colab": {}
      },
      "source": [
        "#Drop 'timestamp' column\n",
        "training_set= training_set.drop([\"timestamp\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FOrgdwIiF9zF",
        "colab": {}
      },
      "source": [
        "#Drop 'timestamp' column\n",
        "test_set= test_set.drop([\"timestamp\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BJ8Aui0cF9zJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ee9b0c02-ee48-4c76-82d1-06eaf3600c6e"
      },
      "source": [
        "# Visualizing the first elements of the training_set\n",
        "training_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  movie_id  rating\n",
              "0        1         1       5\n",
              "1        1         2       3\n",
              "2        1         3       4\n",
              "3        1         4       3\n",
              "4        1         5       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n6XywK6eF9zM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce046020-6889-4eb5-a6d2-9df0b10391ca"
      },
      "source": [
        "training_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b2dmEeYhF9zP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e035ac69-d465-4b49-846d-cef328586393"
      },
      "source": [
        "test_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M3MAecZHF9zR",
        "colab": {}
      },
      "source": [
        "# Converting the training and test sets into numpy arrays\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1h0A4saYF9zU",
        "colab": {}
      },
      "source": [
        "# Getting the number of users and movies\n",
        "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m1WzM9btF9zX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d5889568-cfbe-497e-c045-0176abacfa87"
      },
      "source": [
        "print(\"Number of users: {}\".format(nb_users))\n",
        "print(\"Number of movies: {}\".format(nb_movies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users: 943\n",
            "Number of movies: 1682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exT9EnREF9zb",
        "colab": {}
      },
      "source": [
        "def convert(data):\n",
        "    # Initializing an empty list that will take the list of ratings given by a specific user\n",
        "    new_data = []\n",
        "    # Looping over all the users\n",
        "    for id_users in range(1, nb_users + 1):\n",
        "        # We get the id of the movies rated by the current user\n",
        "        id_movies = data[:, 1][data[:, 0] == id_users]\n",
        "        # We get the id of the ratings given by the current_user\n",
        "        id_ratings = data[:, 2][data[:, 0] == id_users]\n",
        "        # \n",
        "        ratings = np.zeros(nb_movies)\n",
        "        # For movies rated by the current user, we replace 0 with the rating\n",
        "        # The first element of ratings is at index 0. However, id_movies start at index 1.\n",
        "        # Therefore, ratings[id_movies - 1] will correspond to the location of the movie we're considering\n",
        "        ratings[id_movies - 1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JiF2U1OPF9zd",
        "colab": {}
      },
      "source": [
        "# Applying the convert function to the training and test set.\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_R2n7atnF9zg",
        "colab": {}
      },
      "source": [
        "# Convert the data into Torch tensors\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "opaC9JCtF9zj",
        "colab": {}
      },
      "source": [
        "batch_size  = 500\n",
        "\n",
        "''' Dataset Class'''\n",
        "class DatasetR(Dataset):\n",
        "    \"\"\"Youtube-VOS dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, training_set, nb_users, transform=None):\n",
        "        super(DatasetR, self).__init__()\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.training_set = training_set\n",
        "        self.nb_users = nb_users\n",
        "    def __len__(self):\n",
        "        return self.nb_users\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #print(idx)\n",
        "        sample = self.training_set[idx]\n",
        "\n",
        "\n",
        "        #sample = torch.Tensor(sample)\n",
        "\n",
        "\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "isVpFutIF9zl",
        "colab": {}
      },
      "source": [
        "class SAE(nn.Module):\n",
        "    # Initializing the class\n",
        "    def __init__(self, ):\n",
        "        # making the class get all the functions from the parent class nn.Module\n",
        "        super(SAE, self).__init__()\n",
        "        # Creating the first encoding layer. The number of input corresponds to the number of movies\n",
        "        #  Decide to encode it into 20 outputs\n",
        "        self.fc1 = nn.Linear(nb_movies, 20)\n",
        "        # Batch Normalization.\n",
        "        self.bn1 = nn.BatchNorm1d(20)\n",
        "        # Creating the second encoding layer. From 20 inputs to 10 outputs\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "        # Batch Normalization.\n",
        "        self.bn2 = nn.BatchNorm1d(10)\n",
        "        # Creating the first decoding layer. From 10 inputs to 20 outputs\n",
        "        self.fc3 = nn.Linear(10, 20)\n",
        "        # Batch Normalization\n",
        "        self.bn3 = nn.BatchNorm1d(20)\n",
        "        # Creating the second hidden layer. From 20 inputs to nb_movies outputs\n",
        "        self.fc4 = nn.Linear(20, nb_movies)\n",
        "        # Creating the activation fucntion which will fire up specific neurons \n",
        "        self.activation = nn.Sigmoid()\n",
        "        \n",
        "        # Creating the function for forward propagation\n",
        "    def forward(self, x):\n",
        "        # x = self.do1(self.bn1(self.activation(self.fc1(x))))\n",
        "        # x = self.do2(self.bn2(self.activation(self.fc2(x))))\n",
        "        # x = self.do3(self.bn3(self.activation(self.fc3(x))))\n",
        "\n",
        "        x = self.bn1(self.activation(self.fc1(x)))\n",
        "        x = self.bn2(self.activation(self.fc2(x)))\n",
        "        x = self.bn3(self.activation(self.fc3(x)))\n",
        "        # With autoencoder, we don't need an activation function for the last decoding part\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "          \n",
        "    def predict(self, x): # x: visible nodes\n",
        "        x = self.forward(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EXKD2bJsF9zq",
        "colab": {}
      },
      "source": [
        " #Creating an instance of our SAE class\n",
        "sae = SAE()\n",
        "\n",
        "dataset = DatasetR(training_set = training_set, nb_users = nb_users)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "\n",
        "datasetTest = DatasetR(training_set = test_set, nb_users = nb_users)\n",
        "test_loader = torch.utils.data.DataLoader(datasetTest, batch_size = batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " #Defining a criterion which specifies the metric to minimize. In this case, we want to minimize the MSE (Mean Squared Error)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Defining the algorithm used to minimize the loss function. In this case, we'll use RMSprop\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bcPyiCYxF9zt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f9287828-beb6-47f2-ebcf-86980010e2fc"
      },
      "source": [
        "# Setting the number of epochs\n",
        "\n",
        "alosses = []\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "nb_epoch = 200\n",
        "\n",
        "# Iterating over each epoch\n",
        "\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "\n",
        "    #sae.train()\n",
        "\n",
        "    # Initializing the train_loss which will be updated\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    # Initializing a counter\n",
        "\n",
        "    s = 0.\n",
        "\n",
        "    # Iterating over each user\n",
        "\n",
        "    #for id_user in range(nb_users):\n",
        "\n",
        "    for batch_idx, (sample) in enumerate(train_loader):\n",
        "\n",
        "        # The input corresponds to the ratings given by the current user for each movie\n",
        "\n",
        "        input = Variable(sample)\n",
        "\n",
        "        target = input.clone()\n",
        "\n",
        "        # We don't consider movies NOT rated by the current user. So we specify a conditional statement\n",
        "\n",
        "        if torch.sum(target.data > 0) > 0:\n",
        "\n",
        "            # We use our SAE to get the output from the \n",
        "\n",
        "            #print('input:  '+ str(input.shape))\n",
        "\n",
        "            output = sae(input)\n",
        "\n",
        "            #print(output.shape)\n",
        "\n",
        "            target.require_grad = False\n",
        "\n",
        "            output[target == 0] = 0\n",
        "\n",
        "            # Defining our loss function, comparing the output with the target\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "\n",
        "            # Computing the gradients necessary to adjust the weights\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Updating the train_loss\n",
        "\n",
        "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
        "\n",
        "            s += 1.\n",
        "\n",
        "            # Updating the weights of the neural network\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "    epoch_loss = train_loss / len(train_loader)\n",
        "    alosses.append(epoch_loss)  \n",
        "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
        "time_end = time.time()\n",
        "print('Stacked-Autoencoder(SAE) Training Time : ' +str(round((time_end-time_start)/60,0))+' Minutes. ')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss: tensor(0.1695)\n",
            "epoch: 2 loss: tensor(0.1658)\n",
            "epoch: 3 loss: tensor(0.1659)\n",
            "epoch: 4 loss: tensor(0.1651)\n",
            "epoch: 5 loss: tensor(0.1645)\n",
            "epoch: 6 loss: tensor(0.1638)\n",
            "epoch: 7 loss: tensor(0.1649)\n",
            "epoch: 8 loss: tensor(0.1642)\n",
            "epoch: 9 loss: tensor(0.1637)\n",
            "epoch: 10 loss: tensor(0.1650)\n",
            "epoch: 11 loss: tensor(0.1640)\n",
            "epoch: 12 loss: tensor(0.1625)\n",
            "epoch: 13 loss: tensor(0.1633)\n",
            "epoch: 14 loss: tensor(0.1605)\n",
            "epoch: 15 loss: tensor(0.1611)\n",
            "epoch: 16 loss: tensor(0.1632)\n",
            "epoch: 17 loss: tensor(0.1615)\n",
            "epoch: 18 loss: tensor(0.1621)\n",
            "epoch: 19 loss: tensor(0.1600)\n",
            "epoch: 20 loss: tensor(0.1607)\n",
            "epoch: 21 loss: tensor(0.1610)\n",
            "epoch: 22 loss: tensor(0.1610)\n",
            "epoch: 23 loss: tensor(0.1606)\n",
            "epoch: 24 loss: tensor(0.1598)\n",
            "epoch: 25 loss: tensor(0.1598)\n",
            "epoch: 26 loss: tensor(0.1604)\n",
            "epoch: 27 loss: tensor(0.1611)\n",
            "epoch: 28 loss: tensor(0.1607)\n",
            "epoch: 29 loss: tensor(0.1598)\n",
            "epoch: 30 loss: tensor(0.1597)\n",
            "epoch: 31 loss: tensor(0.1613)\n",
            "epoch: 32 loss: tensor(0.1607)\n",
            "epoch: 33 loss: tensor(0.1587)\n",
            "epoch: 34 loss: tensor(0.1589)\n",
            "epoch: 35 loss: tensor(0.1579)\n",
            "epoch: 36 loss: tensor(0.1601)\n",
            "epoch: 37 loss: tensor(0.1580)\n",
            "epoch: 38 loss: tensor(0.1567)\n",
            "epoch: 39 loss: tensor(0.1587)\n",
            "epoch: 40 loss: tensor(0.1576)\n",
            "epoch: 41 loss: tensor(0.1555)\n",
            "epoch: 42 loss: tensor(0.1567)\n",
            "epoch: 43 loss: tensor(0.1567)\n",
            "epoch: 44 loss: tensor(0.1559)\n",
            "epoch: 45 loss: tensor(0.1546)\n",
            "epoch: 46 loss: tensor(0.1535)\n",
            "epoch: 47 loss: tensor(0.1535)\n",
            "epoch: 48 loss: tensor(0.1528)\n",
            "epoch: 49 loss: tensor(0.1529)\n",
            "epoch: 50 loss: tensor(0.1527)\n",
            "epoch: 51 loss: tensor(0.1526)\n",
            "epoch: 52 loss: tensor(0.1502)\n",
            "epoch: 53 loss: tensor(0.1508)\n",
            "epoch: 54 loss: tensor(0.1491)\n",
            "epoch: 55 loss: tensor(0.1480)\n",
            "epoch: 56 loss: tensor(0.1487)\n",
            "epoch: 57 loss: tensor(0.1477)\n",
            "epoch: 58 loss: tensor(0.1464)\n",
            "epoch: 59 loss: tensor(0.1459)\n",
            "epoch: 60 loss: tensor(0.1450)\n",
            "epoch: 61 loss: tensor(0.1425)\n",
            "epoch: 62 loss: tensor(0.1417)\n",
            "epoch: 63 loss: tensor(0.1420)\n",
            "epoch: 64 loss: tensor(0.1415)\n",
            "epoch: 65 loss: tensor(0.1392)\n",
            "epoch: 66 loss: tensor(0.1378)\n",
            "epoch: 67 loss: tensor(0.1353)\n",
            "epoch: 68 loss: tensor(0.1351)\n",
            "epoch: 69 loss: tensor(0.1355)\n",
            "epoch: 70 loss: tensor(0.1324)\n",
            "epoch: 71 loss: tensor(0.1329)\n",
            "epoch: 72 loss: tensor(0.1302)\n",
            "epoch: 73 loss: tensor(0.1295)\n",
            "epoch: 74 loss: tensor(0.1291)\n",
            "epoch: 75 loss: tensor(0.1257)\n",
            "epoch: 76 loss: tensor(0.1244)\n",
            "epoch: 77 loss: tensor(0.1235)\n",
            "epoch: 78 loss: tensor(0.1216)\n",
            "epoch: 79 loss: tensor(0.1195)\n",
            "epoch: 80 loss: tensor(0.1207)\n",
            "epoch: 81 loss: tensor(0.1177)\n",
            "epoch: 82 loss: tensor(0.1156)\n",
            "epoch: 83 loss: tensor(0.1146)\n",
            "epoch: 84 loss: tensor(0.1140)\n",
            "epoch: 85 loss: tensor(0.1109)\n",
            "epoch: 86 loss: tensor(0.1103)\n",
            "epoch: 87 loss: tensor(0.1098)\n",
            "epoch: 88 loss: tensor(0.1074)\n",
            "epoch: 89 loss: tensor(0.1073)\n",
            "epoch: 90 loss: tensor(0.1052)\n",
            "epoch: 91 loss: tensor(0.1050)\n",
            "epoch: 92 loss: tensor(0.1035)\n",
            "epoch: 93 loss: tensor(0.1023)\n",
            "epoch: 94 loss: tensor(0.1014)\n",
            "epoch: 95 loss: tensor(0.0998)\n",
            "epoch: 96 loss: tensor(0.0986)\n",
            "epoch: 97 loss: tensor(0.0976)\n",
            "epoch: 98 loss: tensor(0.0962)\n",
            "epoch: 99 loss: tensor(0.0958)\n",
            "epoch: 100 loss: tensor(0.0945)\n",
            "epoch: 101 loss: tensor(0.0932)\n",
            "epoch: 102 loss: tensor(0.0938)\n",
            "epoch: 103 loss: tensor(0.0921)\n",
            "epoch: 104 loss: tensor(0.0912)\n",
            "epoch: 105 loss: tensor(0.0901)\n",
            "epoch: 106 loss: tensor(0.0903)\n",
            "epoch: 107 loss: tensor(0.0895)\n",
            "epoch: 108 loss: tensor(0.0882)\n",
            "epoch: 109 loss: tensor(0.0868)\n",
            "epoch: 110 loss: tensor(0.0878)\n",
            "epoch: 111 loss: tensor(0.0865)\n",
            "epoch: 112 loss: tensor(0.0856)\n",
            "epoch: 113 loss: tensor(0.0835)\n",
            "epoch: 114 loss: tensor(0.0844)\n",
            "epoch: 115 loss: tensor(0.0833)\n",
            "epoch: 116 loss: tensor(0.0833)\n",
            "epoch: 117 loss: tensor(0.0831)\n",
            "epoch: 118 loss: tensor(0.0828)\n",
            "epoch: 119 loss: tensor(0.0809)\n",
            "epoch: 120 loss: tensor(0.0806)\n",
            "epoch: 121 loss: tensor(0.0801)\n",
            "epoch: 122 loss: tensor(0.0796)\n",
            "epoch: 123 loss: tensor(0.0804)\n",
            "epoch: 124 loss: tensor(0.0793)\n",
            "epoch: 125 loss: tensor(0.0786)\n",
            "epoch: 126 loss: tensor(0.0773)\n",
            "epoch: 127 loss: tensor(0.0767)\n",
            "epoch: 128 loss: tensor(0.0775)\n",
            "epoch: 129 loss: tensor(0.0762)\n",
            "epoch: 130 loss: tensor(0.0749)\n",
            "epoch: 131 loss: tensor(0.0747)\n",
            "epoch: 132 loss: tensor(0.0751)\n",
            "epoch: 133 loss: tensor(0.0742)\n",
            "epoch: 134 loss: tensor(0.0742)\n",
            "epoch: 135 loss: tensor(0.0729)\n",
            "epoch: 136 loss: tensor(0.0738)\n",
            "epoch: 137 loss: tensor(0.0727)\n",
            "epoch: 138 loss: tensor(0.0722)\n",
            "epoch: 139 loss: tensor(0.0729)\n",
            "epoch: 140 loss: tensor(0.0706)\n",
            "epoch: 141 loss: tensor(0.0719)\n",
            "epoch: 142 loss: tensor(0.0703)\n",
            "epoch: 143 loss: tensor(0.0700)\n",
            "epoch: 144 loss: tensor(0.0694)\n",
            "epoch: 145 loss: tensor(0.0699)\n",
            "epoch: 146 loss: tensor(0.0692)\n",
            "epoch: 147 loss: tensor(0.0682)\n",
            "epoch: 148 loss: tensor(0.0688)\n",
            "epoch: 149 loss: tensor(0.0687)\n",
            "epoch: 150 loss: tensor(0.0688)\n",
            "epoch: 151 loss: tensor(0.0691)\n",
            "epoch: 152 loss: tensor(0.0682)\n",
            "epoch: 153 loss: tensor(0.0684)\n",
            "epoch: 154 loss: tensor(0.0677)\n",
            "epoch: 155 loss: tensor(0.0671)\n",
            "epoch: 156 loss: tensor(0.0665)\n",
            "epoch: 157 loss: tensor(0.0672)\n",
            "epoch: 158 loss: tensor(0.0663)\n",
            "epoch: 159 loss: tensor(0.0666)\n",
            "epoch: 160 loss: tensor(0.0660)\n",
            "epoch: 161 loss: tensor(0.0665)\n",
            "epoch: 162 loss: tensor(0.0650)\n",
            "epoch: 163 loss: tensor(0.0653)\n",
            "epoch: 164 loss: tensor(0.0645)\n",
            "epoch: 165 loss: tensor(0.0645)\n",
            "epoch: 166 loss: tensor(0.0639)\n",
            "epoch: 167 loss: tensor(0.0640)\n",
            "epoch: 168 loss: tensor(0.0637)\n",
            "epoch: 169 loss: tensor(0.0635)\n",
            "epoch: 170 loss: tensor(0.0634)\n",
            "epoch: 171 loss: tensor(0.0622)\n",
            "epoch: 172 loss: tensor(0.0634)\n",
            "epoch: 173 loss: tensor(0.0621)\n",
            "epoch: 174 loss: tensor(0.0623)\n",
            "epoch: 175 loss: tensor(0.0630)\n",
            "epoch: 176 loss: tensor(0.0627)\n",
            "epoch: 177 loss: tensor(0.0625)\n",
            "epoch: 178 loss: tensor(0.0619)\n",
            "epoch: 179 loss: tensor(0.0617)\n",
            "epoch: 180 loss: tensor(0.0620)\n",
            "epoch: 181 loss: tensor(0.0611)\n",
            "epoch: 182 loss: tensor(0.0608)\n",
            "epoch: 183 loss: tensor(0.0613)\n",
            "epoch: 184 loss: tensor(0.0601)\n",
            "epoch: 185 loss: tensor(0.0614)\n",
            "epoch: 186 loss: tensor(0.0605)\n",
            "epoch: 187 loss: tensor(0.0609)\n",
            "epoch: 188 loss: tensor(0.0606)\n",
            "epoch: 189 loss: tensor(0.0593)\n",
            "epoch: 190 loss: tensor(0.0592)\n",
            "epoch: 191 loss: tensor(0.0594)\n",
            "epoch: 192 loss: tensor(0.0598)\n",
            "epoch: 193 loss: tensor(0.0596)\n",
            "epoch: 194 loss: tensor(0.0591)\n",
            "epoch: 195 loss: tensor(0.0592)\n",
            "epoch: 196 loss: tensor(0.0585)\n",
            "epoch: 197 loss: tensor(0.0589)\n",
            "epoch: 198 loss: tensor(0.0586)\n",
            "epoch: 199 loss: tensor(0.0585)\n",
            "epoch: 200 loss: tensor(0.0583)\n",
            "Stacked-Autoencoder(SAE) Training Time : 1.0 Minutes. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VyRo9YUgF9zx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "005a2a52-7fbf-4b49-d011-1771dbdfcef0"
      },
      "source": [
        "epochs = range(1,201)\n",
        "plt.plot(epochs, alosses, 'r', label='batch size = 500 ') # 'g' = color green\n",
        "plt.title('Batch Normalization- epoch = 200')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KFz_Ct7lF9z0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5462d60d-79e7-4078-b3a8-cafa3b25cf4f"
      },
      "source": [
        "sae.eval()\n",
        "with torch.no_grad():\n",
        "  test_loss = 0\n",
        "  s = 0.\n",
        "  for input1,target1 in zip(train_loader,test_loader):\n",
        "      input = Variable(input1)\n",
        "      target = Variable(target1)\n",
        "      if torch.sum(target.data > 0) > 0:\n",
        "          output = sae(input)\n",
        "          target.require_grad = False\n",
        "          output[(target == 0)] = 0\n",
        "          loss = criterion(output, target)\n",
        "          mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "          test_loss += np.sqrt(loss.data*mean_corrector)\n",
        "          s += 1.\n",
        "  print('test_loss: '+str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss: tensor(0.0619)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVxLdKIQKJkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "29gKOb3CKJ7b",
        "colab": {}
      },
      "source": [
        "from math import sqrt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d63DldRDKJ7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a8827e0-03cb-4e8c-9402-3518eee47ba2"
      },
      "source": [
        "RMSE = sqrt(0.0619)\n",
        "\n",
        "RMSE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24879710609249456"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBf_xAh9KPDK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5aff2ad4-3b86-48de-aded-2d4a2deecfef"
      },
      "source": [
        "epochs = range(1,201)\n",
        "plt.plot(epochs, losses, 'g', label='batch size = 200 ') # 'g' = color green\n",
        "plt.plot(epochs, alosses, 'r', label='batch size = 500 ') # 'g' = color green\n",
        "plt.title('Batch Normalization- epoch = 200')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PlJ6uA5K1ZI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic6qgDwYK1vP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqfAgXs7tzem",
        "colab_type": "text"
      },
      "source": [
        "# Other Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hKi7WVfkK2Hx"
      },
      "source": [
        "# Batch size 500 plus epoch size 500\n",
        "\n",
        "*   TRAINING LOSS: 0.0474\n",
        "*   TEST LOSS: 0.0512\n",
        "*   RMSE LOSS:0.2262\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ozVM56SOK2Hz",
        "colab": {}
      },
      "source": [
        "training = ['user_id', 'movie_id', 'rating', 'timestamp' ] #Create each column\n",
        "test = ['user_id', 'movie_id', 'rating', 'timestamp' ]     #Create each column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yWV1rF41K2H2",
        "colab": {}
      },
      "source": [
        "# Preparing the training set and the test set \n",
        "training_set = pd.read_csv('u1.base', names=training, delimiter = '\\t') # Read the file\n",
        "test_set = pd.read_csv('u1.test', names=test, delimiter = '\\t') #Read the file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNHIszerK2H5",
        "colab": {}
      },
      "source": [
        "#Drop 'timestamp' column\n",
        "training_set= training_set.drop([\"timestamp\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H9DLw7fBK2H7",
        "colab": {}
      },
      "source": [
        "#Drop 'timestamp' column\n",
        "test_set= test_set.drop([\"timestamp\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8lCGh6OK2IA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ac788788-961f-4351-d36b-3dda7d09f118"
      },
      "source": [
        "# Visualizing the first elements of the training_set\n",
        "training_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  movie_id  rating\n",
              "0        1         1       5\n",
              "1        1         2       3\n",
              "2        1         3       4\n",
              "3        1         4       3\n",
              "4        1         5       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vtWsWON-K2ID",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33414c0b-d39f-4495-848b-4ea4a3621a67"
      },
      "source": [
        "training_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_pipSJaPK2IF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0191cb2e-cd79-407a-9b4f-67a58c86d17d"
      },
      "source": [
        "test_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QkfTjRJfK2IH",
        "colab": {}
      },
      "source": [
        "# Converting the training and test sets into numpy arrays\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T7PNqclLK2IJ",
        "colab": {}
      },
      "source": [
        "# Getting the number of users and movies\n",
        "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VFMjxIwNK2IN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "66fa755b-56e6-46bc-948b-8457e23b5880"
      },
      "source": [
        "print(\"Number of users: {}\".format(nb_users))\n",
        "print(\"Number of movies: {}\".format(nb_movies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users: 943\n",
            "Number of movies: 1682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "anUGXfuMK2IP",
        "colab": {}
      },
      "source": [
        "def convert(data):\n",
        "    # Initializing an empty list that will take the list of ratings given by a specific user\n",
        "    new_data = []\n",
        "    # Looping over all the users\n",
        "    for id_users in range(1, nb_users + 1):\n",
        "        # We get the id of the movies rated by the current user\n",
        "        id_movies = data[:, 1][data[:, 0] == id_users]\n",
        "        # We get the id of the ratings given by the current_user\n",
        "        id_ratings = data[:, 2][data[:, 0] == id_users]\n",
        "        # \n",
        "        ratings = np.zeros(nb_movies)\n",
        "        # For movies rated by the current user, we replace 0 with the rating\n",
        "        # The first element of ratings is at index 0. However, id_movies start at index 1.\n",
        "        # Therefore, ratings[id_movies - 1] will correspond to the location of the movie we're considering\n",
        "        ratings[id_movies - 1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q6NUahY2K2IT",
        "colab": {}
      },
      "source": [
        "# Applying the convert function to the training and test set.\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "51vcNKPSK2IV",
        "colab": {}
      },
      "source": [
        "# Convert the data into Torch tensors\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qSvWjga6K2IY",
        "colab": {}
      },
      "source": [
        "batch_size  = 500\n",
        "\n",
        "''' Dataset Class'''\n",
        "class DatasetR(Dataset):\n",
        "    \"\"\"Youtube-VOS dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, training_set, nb_users, transform=None):\n",
        "        super(DatasetR, self).__init__()\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.training_set = training_set\n",
        "        self.nb_users = nb_users\n",
        "    def __len__(self):\n",
        "        return self.nb_users\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #print(idx)\n",
        "        sample = self.training_set[idx]\n",
        "\n",
        "\n",
        "        #sample = torch.Tensor(sample)\n",
        "\n",
        "\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7fOGt_YsK2IZ",
        "colab": {}
      },
      "source": [
        "class SAE(nn.Module):\n",
        "    # Initializing the class\n",
        "    def __init__(self, ):\n",
        "        # making the class get all the functions from the parent class nn.Module\n",
        "        super(SAE, self).__init__()\n",
        "        # Creating the first encoding layer. The number of input corresponds to the number of movies\n",
        "        #  Decide to encode it into 20 outputs\n",
        "        self.fc1 = nn.Linear(nb_movies, 20)\n",
        "        # Batch Normalization.\n",
        "        self.bn1 = nn.BatchNorm1d(20)\n",
        "        # Creating the second encoding layer. From 20 inputs to 10 outputs\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "        # Batch Normalization.\n",
        "        self.bn2 = nn.BatchNorm1d(10)\n",
        "        # Creating the first decoding layer. From 10 inputs to 20 outputs\n",
        "        self.fc3 = nn.Linear(10, 20)\n",
        "        # Batch Normalization\n",
        "        self.bn3 = nn.BatchNorm1d(20)\n",
        "        # Creating the second hidden layer. From 20 inputs to nb_movies outputs\n",
        "        self.fc4 = nn.Linear(20, nb_movies)\n",
        "        # Creating the activation fucntion which will fire up specific neurons \n",
        "        self.activation = nn.Sigmoid()\n",
        "        \n",
        "        # Creating the function for forward propagation\n",
        "    def forward(self, x):\n",
        "        # x = self.do1(self.bn1(self.activation(self.fc1(x))))\n",
        "        # x = self.do2(self.bn2(self.activation(self.fc2(x))))\n",
        "        # x = self.do3(self.bn3(self.activation(self.fc3(x))))\n",
        "\n",
        "        x = self.bn1(self.activation(self.fc1(x)))\n",
        "        x = self.bn2(self.activation(self.fc2(x)))\n",
        "        x = self.bn3(self.activation(self.fc3(x)))\n",
        "        # With autoencoder, we don't need an activation function for the last decoding part\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "          \n",
        "    def predict(self, x): # x: visible nodes\n",
        "        x = self.forward(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ED8XnzPoK2Ib",
        "colab": {}
      },
      "source": [
        " #Creating an instance of our SAE class\n",
        "sae = SAE()\n",
        "\n",
        "dataset = DatasetR(training_set = training_set, nb_users = nb_users)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "\n",
        "\n",
        "datasetTest = DatasetR(training_set = test_set, nb_users = nb_users)\n",
        "test_loader = torch.utils.data.DataLoader(datasetTest, batch_size = batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " #Defining a criterion which specifies the metric to minimize. In this case, we want to minimize the MSE (Mean Squared Error)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Defining the algorithm used to minimize the loss function. In this case, we'll use RMSprop\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5MpQHWdAK2Id",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4270ac26-e73a-44e5-96f9-62b6ec8c886f"
      },
      "source": [
        "# Setting the number of epochs\n",
        "\n",
        "blosses = []\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "nb_epoch = 500\n",
        "\n",
        "# Iterating over each epoch\n",
        "\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "\n",
        "    #sae.train()\n",
        "\n",
        "    # Initializing the train_loss which will be updated\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    # Initializing a counter\n",
        "\n",
        "    s = 0.\n",
        "\n",
        "    # Iterating over each user\n",
        "\n",
        "    #for id_user in range(nb_users):\n",
        "\n",
        "    for batch_idx, (sample) in enumerate(train_loader):\n",
        "\n",
        "        # The input corresponds to the ratings given by the current user for each movie\n",
        "\n",
        "        input = Variable(sample)\n",
        "\n",
        "        target = input.clone()\n",
        "\n",
        "        # We don't consider movies NOT rated by the current user. So we specify a conditional statement\n",
        "\n",
        "        if torch.sum(target.data > 0) > 0:\n",
        "\n",
        "            # We use our SAE to get the output from the \n",
        "\n",
        "            #print('input:  '+ str(input.shape))\n",
        "\n",
        "            output = sae(input)\n",
        "\n",
        "            #print(output.shape)\n",
        "\n",
        "            target.require_grad = False\n",
        "\n",
        "            output[target == 0] = 0\n",
        "\n",
        "            # Defining our loss function, comparing the output with the target\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "\n",
        "            # Computing the gradients necessary to adjust the weights\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Updating the train_loss\n",
        "\n",
        "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
        "\n",
        "            s += 1.\n",
        "\n",
        "            # Updating the weights of the neural network\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "    epoch_loss = train_loss / len(train_loader)\n",
        "    blosses.append(epoch_loss)  \n",
        "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
        "time_end = time.time()\n",
        "print('Stacked-Autoencoder(SAE) Training Time : ' +str(round((time_end-time_start)/60,0))+' Minutes. ')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss: tensor(0.1690)\n",
            "epoch: 2 loss: tensor(0.1656)\n",
            "epoch: 3 loss: tensor(0.1659)\n",
            "epoch: 4 loss: tensor(0.1648)\n",
            "epoch: 5 loss: tensor(0.1640)\n",
            "epoch: 6 loss: tensor(0.1658)\n",
            "epoch: 7 loss: tensor(0.1651)\n",
            "epoch: 8 loss: tensor(0.1632)\n",
            "epoch: 9 loss: tensor(0.1652)\n",
            "epoch: 10 loss: tensor(0.1632)\n",
            "epoch: 11 loss: tensor(0.1622)\n",
            "epoch: 12 loss: tensor(0.1626)\n",
            "epoch: 13 loss: tensor(0.1615)\n",
            "epoch: 14 loss: tensor(0.1621)\n",
            "epoch: 15 loss: tensor(0.1627)\n",
            "epoch: 16 loss: tensor(0.1620)\n",
            "epoch: 17 loss: tensor(0.1625)\n",
            "epoch: 18 loss: tensor(0.1607)\n",
            "epoch: 19 loss: tensor(0.1610)\n",
            "epoch: 20 loss: tensor(0.1609)\n",
            "epoch: 21 loss: tensor(0.1615)\n",
            "epoch: 22 loss: tensor(0.1621)\n",
            "epoch: 23 loss: tensor(0.1602)\n",
            "epoch: 24 loss: tensor(0.1610)\n",
            "epoch: 25 loss: tensor(0.1613)\n",
            "epoch: 26 loss: tensor(0.1595)\n",
            "epoch: 27 loss: tensor(0.1602)\n",
            "epoch: 28 loss: tensor(0.1605)\n",
            "epoch: 29 loss: tensor(0.1591)\n",
            "epoch: 30 loss: tensor(0.1580)\n",
            "epoch: 31 loss: tensor(0.1593)\n",
            "epoch: 32 loss: tensor(0.1587)\n",
            "epoch: 33 loss: tensor(0.1573)\n",
            "epoch: 34 loss: tensor(0.1580)\n",
            "epoch: 35 loss: tensor(0.1588)\n",
            "epoch: 36 loss: tensor(0.1582)\n",
            "epoch: 37 loss: tensor(0.1572)\n",
            "epoch: 38 loss: tensor(0.1583)\n",
            "epoch: 39 loss: tensor(0.1572)\n",
            "epoch: 40 loss: tensor(0.1552)\n",
            "epoch: 41 loss: tensor(0.1565)\n",
            "epoch: 42 loss: tensor(0.1552)\n",
            "epoch: 43 loss: tensor(0.1571)\n",
            "epoch: 44 loss: tensor(0.1554)\n",
            "epoch: 45 loss: tensor(0.1547)\n",
            "epoch: 46 loss: tensor(0.1529)\n",
            "epoch: 47 loss: tensor(0.1521)\n",
            "epoch: 48 loss: tensor(0.1526)\n",
            "epoch: 49 loss: tensor(0.1518)\n",
            "epoch: 50 loss: tensor(0.1522)\n",
            "epoch: 51 loss: tensor(0.1512)\n",
            "epoch: 52 loss: tensor(0.1491)\n",
            "epoch: 53 loss: tensor(0.1497)\n",
            "epoch: 54 loss: tensor(0.1478)\n",
            "epoch: 55 loss: tensor(0.1474)\n",
            "epoch: 56 loss: tensor(0.1475)\n",
            "epoch: 57 loss: tensor(0.1457)\n",
            "epoch: 58 loss: tensor(0.1443)\n",
            "epoch: 59 loss: tensor(0.1436)\n",
            "epoch: 60 loss: tensor(0.1444)\n",
            "epoch: 61 loss: tensor(0.1413)\n",
            "epoch: 62 loss: tensor(0.1409)\n",
            "epoch: 63 loss: tensor(0.1402)\n",
            "epoch: 64 loss: tensor(0.1378)\n",
            "epoch: 65 loss: tensor(0.1366)\n",
            "epoch: 66 loss: tensor(0.1357)\n",
            "epoch: 67 loss: tensor(0.1362)\n",
            "epoch: 68 loss: tensor(0.1329)\n",
            "epoch: 69 loss: tensor(0.1321)\n",
            "epoch: 70 loss: tensor(0.1303)\n",
            "epoch: 71 loss: tensor(0.1296)\n",
            "epoch: 72 loss: tensor(0.1275)\n",
            "epoch: 73 loss: tensor(0.1266)\n",
            "epoch: 74 loss: tensor(0.1253)\n",
            "epoch: 75 loss: tensor(0.1240)\n",
            "epoch: 76 loss: tensor(0.1238)\n",
            "epoch: 77 loss: tensor(0.1209)\n",
            "epoch: 78 loss: tensor(0.1189)\n",
            "epoch: 79 loss: tensor(0.1195)\n",
            "epoch: 80 loss: tensor(0.1160)\n",
            "epoch: 81 loss: tensor(0.1146)\n",
            "epoch: 82 loss: tensor(0.1135)\n",
            "epoch: 83 loss: tensor(0.1129)\n",
            "epoch: 84 loss: tensor(0.1110)\n",
            "epoch: 85 loss: tensor(0.1106)\n",
            "epoch: 86 loss: tensor(0.1085)\n",
            "epoch: 87 loss: tensor(0.1069)\n",
            "epoch: 88 loss: tensor(0.1049)\n",
            "epoch: 89 loss: tensor(0.1060)\n",
            "epoch: 90 loss: tensor(0.1034)\n",
            "epoch: 91 loss: tensor(0.1029)\n",
            "epoch: 92 loss: tensor(0.1015)\n",
            "epoch: 93 loss: tensor(0.1000)\n",
            "epoch: 94 loss: tensor(0.0993)\n",
            "epoch: 95 loss: tensor(0.0966)\n",
            "epoch: 96 loss: tensor(0.0971)\n",
            "epoch: 97 loss: tensor(0.0951)\n",
            "epoch: 98 loss: tensor(0.0946)\n",
            "epoch: 99 loss: tensor(0.0936)\n",
            "epoch: 100 loss: tensor(0.0941)\n",
            "epoch: 101 loss: tensor(0.0910)\n",
            "epoch: 102 loss: tensor(0.0919)\n",
            "epoch: 103 loss: tensor(0.0912)\n",
            "epoch: 104 loss: tensor(0.0904)\n",
            "epoch: 105 loss: tensor(0.0879)\n",
            "epoch: 106 loss: tensor(0.0881)\n",
            "epoch: 107 loss: tensor(0.0877)\n",
            "epoch: 108 loss: tensor(0.0861)\n",
            "epoch: 109 loss: tensor(0.0856)\n",
            "epoch: 110 loss: tensor(0.0851)\n",
            "epoch: 111 loss: tensor(0.0841)\n",
            "epoch: 112 loss: tensor(0.0846)\n",
            "epoch: 113 loss: tensor(0.0837)\n",
            "epoch: 114 loss: tensor(0.0841)\n",
            "epoch: 115 loss: tensor(0.0822)\n",
            "epoch: 116 loss: tensor(0.0827)\n",
            "epoch: 117 loss: tensor(0.0815)\n",
            "epoch: 118 loss: tensor(0.0809)\n",
            "epoch: 119 loss: tensor(0.0805)\n",
            "epoch: 120 loss: tensor(0.0802)\n",
            "epoch: 121 loss: tensor(0.0804)\n",
            "epoch: 122 loss: tensor(0.0796)\n",
            "epoch: 123 loss: tensor(0.0778)\n",
            "epoch: 124 loss: tensor(0.0788)\n",
            "epoch: 125 loss: tensor(0.0770)\n",
            "epoch: 126 loss: tensor(0.0776)\n",
            "epoch: 127 loss: tensor(0.0770)\n",
            "epoch: 128 loss: tensor(0.0762)\n",
            "epoch: 129 loss: tensor(0.0763)\n",
            "epoch: 130 loss: tensor(0.0756)\n",
            "epoch: 131 loss: tensor(0.0745)\n",
            "epoch: 132 loss: tensor(0.0741)\n",
            "epoch: 133 loss: tensor(0.0744)\n",
            "epoch: 134 loss: tensor(0.0737)\n",
            "epoch: 135 loss: tensor(0.0742)\n",
            "epoch: 136 loss: tensor(0.0737)\n",
            "epoch: 137 loss: tensor(0.0726)\n",
            "epoch: 138 loss: tensor(0.0713)\n",
            "epoch: 139 loss: tensor(0.0724)\n",
            "epoch: 140 loss: tensor(0.0712)\n",
            "epoch: 141 loss: tensor(0.0716)\n",
            "epoch: 142 loss: tensor(0.0703)\n",
            "epoch: 143 loss: tensor(0.0695)\n",
            "epoch: 144 loss: tensor(0.0701)\n",
            "epoch: 145 loss: tensor(0.0696)\n",
            "epoch: 146 loss: tensor(0.0694)\n",
            "epoch: 147 loss: tensor(0.0697)\n",
            "epoch: 148 loss: tensor(0.0682)\n",
            "epoch: 149 loss: tensor(0.0691)\n",
            "epoch: 150 loss: tensor(0.0678)\n",
            "epoch: 151 loss: tensor(0.0687)\n",
            "epoch: 152 loss: tensor(0.0683)\n",
            "epoch: 153 loss: tensor(0.0677)\n",
            "epoch: 154 loss: tensor(0.0669)\n",
            "epoch: 155 loss: tensor(0.0681)\n",
            "epoch: 156 loss: tensor(0.0669)\n",
            "epoch: 157 loss: tensor(0.0669)\n",
            "epoch: 158 loss: tensor(0.0660)\n",
            "epoch: 159 loss: tensor(0.0661)\n",
            "epoch: 160 loss: tensor(0.0649)\n",
            "epoch: 161 loss: tensor(0.0652)\n",
            "epoch: 162 loss: tensor(0.0645)\n",
            "epoch: 163 loss: tensor(0.0654)\n",
            "epoch: 164 loss: tensor(0.0649)\n",
            "epoch: 165 loss: tensor(0.0648)\n",
            "epoch: 166 loss: tensor(0.0650)\n",
            "epoch: 167 loss: tensor(0.0644)\n",
            "epoch: 168 loss: tensor(0.0635)\n",
            "epoch: 169 loss: tensor(0.0641)\n",
            "epoch: 170 loss: tensor(0.0643)\n",
            "epoch: 171 loss: tensor(0.0633)\n",
            "epoch: 172 loss: tensor(0.0628)\n",
            "epoch: 173 loss: tensor(0.0625)\n",
            "epoch: 174 loss: tensor(0.0631)\n",
            "epoch: 175 loss: tensor(0.0612)\n",
            "epoch: 176 loss: tensor(0.0620)\n",
            "epoch: 177 loss: tensor(0.0617)\n",
            "epoch: 178 loss: tensor(0.0615)\n",
            "epoch: 179 loss: tensor(0.0620)\n",
            "epoch: 180 loss: tensor(0.0609)\n",
            "epoch: 181 loss: tensor(0.0610)\n",
            "epoch: 182 loss: tensor(0.0603)\n",
            "epoch: 183 loss: tensor(0.0618)\n",
            "epoch: 184 loss: tensor(0.0605)\n",
            "epoch: 185 loss: tensor(0.0612)\n",
            "epoch: 186 loss: tensor(0.0608)\n",
            "epoch: 187 loss: tensor(0.0605)\n",
            "epoch: 188 loss: tensor(0.0604)\n",
            "epoch: 189 loss: tensor(0.0588)\n",
            "epoch: 190 loss: tensor(0.0603)\n",
            "epoch: 191 loss: tensor(0.0607)\n",
            "epoch: 192 loss: tensor(0.0592)\n",
            "epoch: 193 loss: tensor(0.0601)\n",
            "epoch: 194 loss: tensor(0.0586)\n",
            "epoch: 195 loss: tensor(0.0597)\n",
            "epoch: 196 loss: tensor(0.0592)\n",
            "epoch: 197 loss: tensor(0.0589)\n",
            "epoch: 198 loss: tensor(0.0589)\n",
            "epoch: 199 loss: tensor(0.0582)\n",
            "epoch: 200 loss: tensor(0.0581)\n",
            "epoch: 201 loss: tensor(0.0591)\n",
            "epoch: 202 loss: tensor(0.0582)\n",
            "epoch: 203 loss: tensor(0.0588)\n",
            "epoch: 204 loss: tensor(0.0577)\n",
            "epoch: 205 loss: tensor(0.0583)\n",
            "epoch: 206 loss: tensor(0.0582)\n",
            "epoch: 207 loss: tensor(0.0580)\n",
            "epoch: 208 loss: tensor(0.0571)\n",
            "epoch: 209 loss: tensor(0.0564)\n",
            "epoch: 210 loss: tensor(0.0574)\n",
            "epoch: 211 loss: tensor(0.0562)\n",
            "epoch: 212 loss: tensor(0.0567)\n",
            "epoch: 213 loss: tensor(0.0576)\n",
            "epoch: 214 loss: tensor(0.0561)\n",
            "epoch: 215 loss: tensor(0.0570)\n",
            "epoch: 216 loss: tensor(0.0561)\n",
            "epoch: 217 loss: tensor(0.0570)\n",
            "epoch: 218 loss: tensor(0.0562)\n",
            "epoch: 219 loss: tensor(0.0568)\n",
            "epoch: 220 loss: tensor(0.0563)\n",
            "epoch: 221 loss: tensor(0.0563)\n",
            "epoch: 222 loss: tensor(0.0566)\n",
            "epoch: 223 loss: tensor(0.0564)\n",
            "epoch: 224 loss: tensor(0.0557)\n",
            "epoch: 225 loss: tensor(0.0551)\n",
            "epoch: 226 loss: tensor(0.0555)\n",
            "epoch: 227 loss: tensor(0.0554)\n",
            "epoch: 228 loss: tensor(0.0552)\n",
            "epoch: 229 loss: tensor(0.0548)\n",
            "epoch: 230 loss: tensor(0.0552)\n",
            "epoch: 231 loss: tensor(0.0557)\n",
            "epoch: 232 loss: tensor(0.0549)\n",
            "epoch: 233 loss: tensor(0.0557)\n",
            "epoch: 234 loss: tensor(0.0550)\n",
            "epoch: 235 loss: tensor(0.0554)\n",
            "epoch: 236 loss: tensor(0.0551)\n",
            "epoch: 237 loss: tensor(0.0541)\n",
            "epoch: 238 loss: tensor(0.0541)\n",
            "epoch: 239 loss: tensor(0.0558)\n",
            "epoch: 240 loss: tensor(0.0547)\n",
            "epoch: 241 loss: tensor(0.0535)\n",
            "epoch: 242 loss: tensor(0.0537)\n",
            "epoch: 243 loss: tensor(0.0539)\n",
            "epoch: 244 loss: tensor(0.0535)\n",
            "epoch: 245 loss: tensor(0.0546)\n",
            "epoch: 246 loss: tensor(0.0554)\n",
            "epoch: 247 loss: tensor(0.0541)\n",
            "epoch: 248 loss: tensor(0.0531)\n",
            "epoch: 249 loss: tensor(0.0545)\n",
            "epoch: 250 loss: tensor(0.0531)\n",
            "epoch: 251 loss: tensor(0.0529)\n",
            "epoch: 252 loss: tensor(0.0536)\n",
            "epoch: 253 loss: tensor(0.0526)\n",
            "epoch: 254 loss: tensor(0.0535)\n",
            "epoch: 255 loss: tensor(0.0533)\n",
            "epoch: 256 loss: tensor(0.0542)\n",
            "epoch: 257 loss: tensor(0.0531)\n",
            "epoch: 258 loss: tensor(0.0527)\n",
            "epoch: 259 loss: tensor(0.0545)\n",
            "epoch: 260 loss: tensor(0.0527)\n",
            "epoch: 261 loss: tensor(0.0530)\n",
            "epoch: 262 loss: tensor(0.0532)\n",
            "epoch: 263 loss: tensor(0.0543)\n",
            "epoch: 264 loss: tensor(0.0533)\n",
            "epoch: 265 loss: tensor(0.0536)\n",
            "epoch: 266 loss: tensor(0.0527)\n",
            "epoch: 267 loss: tensor(0.0540)\n",
            "epoch: 268 loss: tensor(0.0536)\n",
            "epoch: 269 loss: tensor(0.0535)\n",
            "epoch: 270 loss: tensor(0.0534)\n",
            "epoch: 271 loss: tensor(0.0527)\n",
            "epoch: 272 loss: tensor(0.0537)\n",
            "epoch: 273 loss: tensor(0.0527)\n",
            "epoch: 274 loss: tensor(0.0521)\n",
            "epoch: 275 loss: tensor(0.0536)\n",
            "epoch: 276 loss: tensor(0.0527)\n",
            "epoch: 277 loss: tensor(0.0526)\n",
            "epoch: 278 loss: tensor(0.0522)\n",
            "epoch: 279 loss: tensor(0.0527)\n",
            "epoch: 280 loss: tensor(0.0517)\n",
            "epoch: 281 loss: tensor(0.0525)\n",
            "epoch: 282 loss: tensor(0.0515)\n",
            "epoch: 283 loss: tensor(0.0523)\n",
            "epoch: 284 loss: tensor(0.0523)\n",
            "epoch: 285 loss: tensor(0.0533)\n",
            "epoch: 286 loss: tensor(0.0524)\n",
            "epoch: 287 loss: tensor(0.0519)\n",
            "epoch: 288 loss: tensor(0.0521)\n",
            "epoch: 289 loss: tensor(0.0519)\n",
            "epoch: 290 loss: tensor(0.0517)\n",
            "epoch: 291 loss: tensor(0.0523)\n",
            "epoch: 292 loss: tensor(0.0518)\n",
            "epoch: 293 loss: tensor(0.0517)\n",
            "epoch: 294 loss: tensor(0.0524)\n",
            "epoch: 295 loss: tensor(0.0520)\n",
            "epoch: 296 loss: tensor(0.0512)\n",
            "epoch: 297 loss: tensor(0.0530)\n",
            "epoch: 298 loss: tensor(0.0517)\n",
            "epoch: 299 loss: tensor(0.0512)\n",
            "epoch: 300 loss: tensor(0.0508)\n",
            "epoch: 301 loss: tensor(0.0508)\n",
            "epoch: 302 loss: tensor(0.0515)\n",
            "epoch: 303 loss: tensor(0.0522)\n",
            "epoch: 304 loss: tensor(0.0505)\n",
            "epoch: 305 loss: tensor(0.0521)\n",
            "epoch: 306 loss: tensor(0.0509)\n",
            "epoch: 307 loss: tensor(0.0515)\n",
            "epoch: 308 loss: tensor(0.0509)\n",
            "epoch: 309 loss: tensor(0.0513)\n",
            "epoch: 310 loss: tensor(0.0509)\n",
            "epoch: 311 loss: tensor(0.0518)\n",
            "epoch: 312 loss: tensor(0.0526)\n",
            "epoch: 313 loss: tensor(0.0511)\n",
            "epoch: 314 loss: tensor(0.0504)\n",
            "epoch: 315 loss: tensor(0.0514)\n",
            "epoch: 316 loss: tensor(0.0509)\n",
            "epoch: 317 loss: tensor(0.0521)\n",
            "epoch: 318 loss: tensor(0.0507)\n",
            "epoch: 319 loss: tensor(0.0518)\n",
            "epoch: 320 loss: tensor(0.0513)\n",
            "epoch: 321 loss: tensor(0.0523)\n",
            "epoch: 322 loss: tensor(0.0520)\n",
            "epoch: 323 loss: tensor(0.0515)\n",
            "epoch: 324 loss: tensor(0.0517)\n",
            "epoch: 325 loss: tensor(0.0497)\n",
            "epoch: 326 loss: tensor(0.0508)\n",
            "epoch: 327 loss: tensor(0.0512)\n",
            "epoch: 328 loss: tensor(0.0512)\n",
            "epoch: 329 loss: tensor(0.0505)\n",
            "epoch: 330 loss: tensor(0.0508)\n",
            "epoch: 331 loss: tensor(0.0513)\n",
            "epoch: 332 loss: tensor(0.0505)\n",
            "epoch: 333 loss: tensor(0.0512)\n",
            "epoch: 334 loss: tensor(0.0503)\n",
            "epoch: 335 loss: tensor(0.0497)\n",
            "epoch: 336 loss: tensor(0.0503)\n",
            "epoch: 337 loss: tensor(0.0508)\n",
            "epoch: 338 loss: tensor(0.0499)\n",
            "epoch: 339 loss: tensor(0.0510)\n",
            "epoch: 340 loss: tensor(0.0504)\n",
            "epoch: 341 loss: tensor(0.0502)\n",
            "epoch: 342 loss: tensor(0.0498)\n",
            "epoch: 343 loss: tensor(0.0507)\n",
            "epoch: 344 loss: tensor(0.0499)\n",
            "epoch: 345 loss: tensor(0.0503)\n",
            "epoch: 346 loss: tensor(0.0504)\n",
            "epoch: 347 loss: tensor(0.0504)\n",
            "epoch: 348 loss: tensor(0.0503)\n",
            "epoch: 349 loss: tensor(0.0515)\n",
            "epoch: 350 loss: tensor(0.0506)\n",
            "epoch: 351 loss: tensor(0.0504)\n",
            "epoch: 352 loss: tensor(0.0499)\n",
            "epoch: 353 loss: tensor(0.0506)\n",
            "epoch: 354 loss: tensor(0.0496)\n",
            "epoch: 355 loss: tensor(0.0499)\n",
            "epoch: 356 loss: tensor(0.0504)\n",
            "epoch: 357 loss: tensor(0.0501)\n",
            "epoch: 358 loss: tensor(0.0501)\n",
            "epoch: 359 loss: tensor(0.0507)\n",
            "epoch: 360 loss: tensor(0.0505)\n",
            "epoch: 361 loss: tensor(0.0503)\n",
            "epoch: 362 loss: tensor(0.0506)\n",
            "epoch: 363 loss: tensor(0.0526)\n",
            "epoch: 364 loss: tensor(0.0502)\n",
            "epoch: 365 loss: tensor(0.0498)\n",
            "epoch: 366 loss: tensor(0.0498)\n",
            "epoch: 367 loss: tensor(0.0501)\n",
            "epoch: 368 loss: tensor(0.0500)\n",
            "epoch: 369 loss: tensor(0.0492)\n",
            "epoch: 370 loss: tensor(0.0492)\n",
            "epoch: 371 loss: tensor(0.0499)\n",
            "epoch: 372 loss: tensor(0.0496)\n",
            "epoch: 373 loss: tensor(0.0494)\n",
            "epoch: 374 loss: tensor(0.0499)\n",
            "epoch: 375 loss: tensor(0.0497)\n",
            "epoch: 376 loss: tensor(0.0492)\n",
            "epoch: 377 loss: tensor(0.0505)\n",
            "epoch: 378 loss: tensor(0.0498)\n",
            "epoch: 379 loss: tensor(0.0490)\n",
            "epoch: 380 loss: tensor(0.0490)\n",
            "epoch: 381 loss: tensor(0.0499)\n",
            "epoch: 382 loss: tensor(0.0491)\n",
            "epoch: 383 loss: tensor(0.0492)\n",
            "epoch: 384 loss: tensor(0.0498)\n",
            "epoch: 385 loss: tensor(0.0489)\n",
            "epoch: 386 loss: tensor(0.0487)\n",
            "epoch: 387 loss: tensor(0.0491)\n",
            "epoch: 388 loss: tensor(0.0487)\n",
            "epoch: 389 loss: tensor(0.0490)\n",
            "epoch: 390 loss: tensor(0.0490)\n",
            "epoch: 391 loss: tensor(0.0497)\n",
            "epoch: 392 loss: tensor(0.0496)\n",
            "epoch: 393 loss: tensor(0.0497)\n",
            "epoch: 394 loss: tensor(0.0489)\n",
            "epoch: 395 loss: tensor(0.0499)\n",
            "epoch: 396 loss: tensor(0.0494)\n",
            "epoch: 397 loss: tensor(0.0489)\n",
            "epoch: 398 loss: tensor(0.0490)\n",
            "epoch: 399 loss: tensor(0.0489)\n",
            "epoch: 400 loss: tensor(0.0495)\n",
            "epoch: 401 loss: tensor(0.0490)\n",
            "epoch: 402 loss: tensor(0.0492)\n",
            "epoch: 403 loss: tensor(0.0499)\n",
            "epoch: 404 loss: tensor(0.0494)\n",
            "epoch: 405 loss: tensor(0.0477)\n",
            "epoch: 406 loss: tensor(0.0486)\n",
            "epoch: 407 loss: tensor(0.0486)\n",
            "epoch: 408 loss: tensor(0.0487)\n",
            "epoch: 409 loss: tensor(0.0480)\n",
            "epoch: 410 loss: tensor(0.0492)\n",
            "epoch: 411 loss: tensor(0.0483)\n",
            "epoch: 412 loss: tensor(0.0490)\n",
            "epoch: 413 loss: tensor(0.0493)\n",
            "epoch: 414 loss: tensor(0.0486)\n",
            "epoch: 415 loss: tensor(0.0490)\n",
            "epoch: 416 loss: tensor(0.0499)\n",
            "epoch: 417 loss: tensor(0.0486)\n",
            "epoch: 418 loss: tensor(0.0488)\n",
            "epoch: 419 loss: tensor(0.0503)\n",
            "epoch: 420 loss: tensor(0.0489)\n",
            "epoch: 421 loss: tensor(0.0486)\n",
            "epoch: 422 loss: tensor(0.0482)\n",
            "epoch: 423 loss: tensor(0.0487)\n",
            "epoch: 424 loss: tensor(0.0480)\n",
            "epoch: 425 loss: tensor(0.0486)\n",
            "epoch: 426 loss: tensor(0.0484)\n",
            "epoch: 427 loss: tensor(0.0484)\n",
            "epoch: 428 loss: tensor(0.0486)\n",
            "epoch: 429 loss: tensor(0.0488)\n",
            "epoch: 430 loss: tensor(0.0485)\n",
            "epoch: 431 loss: tensor(0.0483)\n",
            "epoch: 432 loss: tensor(0.0483)\n",
            "epoch: 433 loss: tensor(0.0488)\n",
            "epoch: 434 loss: tensor(0.0488)\n",
            "epoch: 435 loss: tensor(0.0485)\n",
            "epoch: 436 loss: tensor(0.0483)\n",
            "epoch: 437 loss: tensor(0.0483)\n",
            "epoch: 438 loss: tensor(0.0482)\n",
            "epoch: 439 loss: tensor(0.0496)\n",
            "epoch: 440 loss: tensor(0.0483)\n",
            "epoch: 441 loss: tensor(0.0485)\n",
            "epoch: 442 loss: tensor(0.0473)\n",
            "epoch: 443 loss: tensor(0.0489)\n",
            "epoch: 444 loss: tensor(0.0481)\n",
            "epoch: 445 loss: tensor(0.0480)\n",
            "epoch: 446 loss: tensor(0.0487)\n",
            "epoch: 447 loss: tensor(0.0490)\n",
            "epoch: 448 loss: tensor(0.0471)\n",
            "epoch: 449 loss: tensor(0.0474)\n",
            "epoch: 450 loss: tensor(0.0480)\n",
            "epoch: 451 loss: tensor(0.0486)\n",
            "epoch: 452 loss: tensor(0.0484)\n",
            "epoch: 453 loss: tensor(0.0478)\n",
            "epoch: 454 loss: tensor(0.0483)\n",
            "epoch: 455 loss: tensor(0.0485)\n",
            "epoch: 456 loss: tensor(0.0481)\n",
            "epoch: 457 loss: tensor(0.0473)\n",
            "epoch: 458 loss: tensor(0.0484)\n",
            "epoch: 459 loss: tensor(0.0484)\n",
            "epoch: 460 loss: tensor(0.0475)\n",
            "epoch: 461 loss: tensor(0.0482)\n",
            "epoch: 462 loss: tensor(0.0475)\n",
            "epoch: 463 loss: tensor(0.0485)\n",
            "epoch: 464 loss: tensor(0.0475)\n",
            "epoch: 465 loss: tensor(0.0476)\n",
            "epoch: 466 loss: tensor(0.0470)\n",
            "epoch: 467 loss: tensor(0.0481)\n",
            "epoch: 468 loss: tensor(0.0475)\n",
            "epoch: 469 loss: tensor(0.0480)\n",
            "epoch: 470 loss: tensor(0.0483)\n",
            "epoch: 471 loss: tensor(0.0483)\n",
            "epoch: 472 loss: tensor(0.0470)\n",
            "epoch: 473 loss: tensor(0.0474)\n",
            "epoch: 474 loss: tensor(0.0468)\n",
            "epoch: 475 loss: tensor(0.0473)\n",
            "epoch: 476 loss: tensor(0.0473)\n",
            "epoch: 477 loss: tensor(0.0482)\n",
            "epoch: 478 loss: tensor(0.0475)\n",
            "epoch: 479 loss: tensor(0.0468)\n",
            "epoch: 480 loss: tensor(0.0478)\n",
            "epoch: 481 loss: tensor(0.0475)\n",
            "epoch: 482 loss: tensor(0.0487)\n",
            "epoch: 483 loss: tensor(0.0477)\n",
            "epoch: 484 loss: tensor(0.0472)\n",
            "epoch: 485 loss: tensor(0.0481)\n",
            "epoch: 486 loss: tensor(0.0478)\n",
            "epoch: 487 loss: tensor(0.0478)\n",
            "epoch: 488 loss: tensor(0.0476)\n",
            "epoch: 489 loss: tensor(0.0478)\n",
            "epoch: 490 loss: tensor(0.0481)\n",
            "epoch: 491 loss: tensor(0.0473)\n",
            "epoch: 492 loss: tensor(0.0478)\n",
            "epoch: 493 loss: tensor(0.0483)\n",
            "epoch: 494 loss: tensor(0.0477)\n",
            "epoch: 495 loss: tensor(0.0465)\n",
            "epoch: 496 loss: tensor(0.0467)\n",
            "epoch: 497 loss: tensor(0.0473)\n",
            "epoch: 498 loss: tensor(0.0472)\n",
            "epoch: 499 loss: tensor(0.0476)\n",
            "epoch: 500 loss: tensor(0.0474)\n",
            "Stacked-Autoencoder(SAE) Training Time : 1.0 Minutes. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7NDOfE2KK2If",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e97a552d-4613-41f2-bdc6-26c6f870202e"
      },
      "source": [
        "epochs = range(1,501)\n",
        "plt.plot(epochs, blosses, 'b', label=' batch size = 500 ') # 'g' = color green\n",
        "plt.title('Batch Normalization- epoch = 500')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Be4TMrqtK2Ih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b8ec134-e960-4d14-ef9e-eefd761b40d2"
      },
      "source": [
        "sae.eval()\n",
        "with torch.no_grad():\n",
        "  test_loss = 0\n",
        "  s = 0.\n",
        "  for input1,target1 in zip(train_loader,test_loader):\n",
        "      input = Variable(input1)\n",
        "      target = Variable(target1)\n",
        "      if torch.sum(target.data > 0) > 0:\n",
        "          output = sae(input)\n",
        "          target.require_grad = False\n",
        "          output[(target == 0)] = 0\n",
        "          loss = criterion(output, target)\n",
        "          mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "          test_loss += np.sqrt(loss.data*mean_corrector)\n",
        "          s += 1.\n",
        "  print('test_loss: '+str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss: tensor(0.0512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sBw4vT9nK2Ij",
        "colab": {}
      },
      "source": [
        "from math import sqrt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HqZTuRaEK2Il",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88698521-8027-4847-9502-959cf5ed50fe"
      },
      "source": [
        "RMSE = sqrt(0.0512)\n",
        "\n",
        "RMSE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2262741699796952"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBdLtoPzOzWL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4eHrg-sOzqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NfqaCZibOz85"
      },
      "source": [
        "# Batch size 500 plus epoch size 1000\n",
        "\n",
        "*   TRAINING LOSS: 0.0441\n",
        "*   TEST LOSS: 0.0478\n",
        "*   RMSE LOSS: 0.2186\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q6A9FRVbOz85",
        "colab": {}
      },
      "source": [
        "training = ['user_id', 'movie_id', 'rating', 'timestamp' ] #Create each column\n",
        "test = ['user_id', 'movie_id', 'rating', 'timestamp' ]     #Create each column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nfA0tSi-Oz88",
        "colab": {}
      },
      "source": [
        "# Preparing the training set and the test set \n",
        "training_set = pd.read_csv('u1.base', names=training, delimiter = '\\t') # Read the file\n",
        "test_set = pd.read_csv('u1.test', names=test, delimiter = '\\t') #Read the file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HYudkGp0Oz8-",
        "colab": {}
      },
      "source": [
        "#Drop 'timestamp' column\n",
        "training_set= training_set.drop([\"timestamp\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cr6LXy2ROz9B",
        "colab": {}
      },
      "source": [
        "#Drop 'timestamp' column\n",
        "test_set= test_set.drop([\"timestamp\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9JWtEvbXOz9E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5f9f1c4f-d3da-4d1f-e76b-669040103b01"
      },
      "source": [
        "# Visualizing the first elements of the training_set\n",
        "training_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  movie_id  rating\n",
              "0        1         1       5\n",
              "1        1         2       3\n",
              "2        1         3       4\n",
              "3        1         4       3\n",
              "4        1         5       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_9dHnjFiOz9G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfa2bdbe-443c-4d21-9dff-551776bbc6e1"
      },
      "source": [
        "training_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B5rfyyvaOz9I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5afc57a6-1982-4085-821f-9b199c67832d"
      },
      "source": [
        "test_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bn_N8P63Oz9L",
        "colab": {}
      },
      "source": [
        "# Converting the training and test sets into numpy arrays\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_PkRyoRpOz9N",
        "colab": {}
      },
      "source": [
        "# Getting the number of users and movies\n",
        "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W-ZDA0lUOz9P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "403ecb69-24bb-4d04-9d7c-fb4fb53f1a33"
      },
      "source": [
        "print(\"Number of users: {}\".format(nb_users))\n",
        "print(\"Number of movies: {}\".format(nb_movies))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users: 943\n",
            "Number of movies: 1682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SUHJIl27Oz9S",
        "colab": {}
      },
      "source": [
        "def convert(data):\n",
        "    # Initializing an empty list that will take the list of ratings given by a specific user\n",
        "    new_data = []\n",
        "    # Looping over all the users\n",
        "    for id_users in range(1, nb_users + 1):\n",
        "        # We get the id of the movies rated by the current user\n",
        "        id_movies = data[:, 1][data[:, 0] == id_users]\n",
        "        # We get the id of the ratings given by the current_user\n",
        "        id_ratings = data[:, 2][data[:, 0] == id_users]\n",
        "        # \n",
        "        ratings = np.zeros(nb_movies)\n",
        "        # For movies rated by the current user, we replace 0 with the rating\n",
        "        # The first element of ratings is at index 0. However, id_movies start at index 1.\n",
        "        # Therefore, ratings[id_movies - 1] will correspond to the location of the movie we're considering\n",
        "        ratings[id_movies - 1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LuIZwYBjOz9X",
        "colab": {}
      },
      "source": [
        "# Applying the convert function to the training and test set.\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hv3rFWbpOz9Z",
        "colab": {}
      },
      "source": [
        "# Convert the data into Torch tensors\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "62tX4XvMOz9b",
        "colab": {}
      },
      "source": [
        "batch_size  = 500\n",
        "\n",
        "''' Dataset Class'''\n",
        "class DatasetR(Dataset):\n",
        "    \"\"\"Youtube-VOS dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, training_set, nb_users, transform=None):\n",
        "        super(DatasetR, self).__init__()\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.training_set = training_set\n",
        "        self.nb_users = nb_users\n",
        "    def __len__(self):\n",
        "        return self.nb_users\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #print(idx)\n",
        "        sample = self.training_set[idx]\n",
        "\n",
        "\n",
        "        #sample = torch.Tensor(sample)\n",
        "\n",
        "\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U6OuO2aROz9d",
        "colab": {}
      },
      "source": [
        "class SAE(nn.Module):\n",
        "    # Initializing the class\n",
        "    def __init__(self, ):\n",
        "        # making the class get all the functions from the parent class nn.Module\n",
        "        super(SAE, self).__init__()\n",
        "        # Creating the first encoding layer. The number of input corresponds to the number of movies\n",
        "        #  Decide to encode it into 20 outputs\n",
        "        self.fc1 = nn.Linear(nb_movies, 20)\n",
        "        # Batch Normalization.\n",
        "        self.bn1 = nn.BatchNorm1d(20)\n",
        "        # Creating the second encoding layer. From 20 inputs to 10 outputs\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "        # Batch Normalization.\n",
        "        self.bn2 = nn.BatchNorm1d(10)\n",
        "        # Creating the first decoding layer. From 10 inputs to 20 outputs\n",
        "        self.fc3 = nn.Linear(10, 20)\n",
        "        # Batch Normalization\n",
        "        self.bn3 = nn.BatchNorm1d(20)\n",
        "        # Creating the second hidden layer. From 20 inputs to nb_movies outputs\n",
        "        self.fc4 = nn.Linear(20, nb_movies)\n",
        "        # Creating the activation fucntion which will fire up specific neurons \n",
        "        self.activation = nn.Sigmoid()\n",
        "        \n",
        "        # Creating the function for forward propagation\n",
        "    def forward(self, x):\n",
        "        # x = self.do1(self.bn1(self.activation(self.fc1(x))))\n",
        "        # x = self.do2(self.bn2(self.activation(self.fc2(x))))\n",
        "        # x = self.do3(self.bn3(self.activation(self.fc3(x))))\n",
        "\n",
        "        x = self.bn1(self.activation(self.fc1(x)))\n",
        "        x = self.bn2(self.activation(self.fc2(x)))\n",
        "        x = self.bn3(self.activation(self.fc3(x)))\n",
        "        # With autoencoder, we don't need an activation function for the last decoding part\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "          \n",
        "    def predict(self, x): # x: visible nodes\n",
        "        x = self.forward(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4gSVL-4qOz9g",
        "colab": {}
      },
      "source": [
        " #Creating an instance of our SAE class\n",
        "sae = SAE()\n",
        "\n",
        "dataset = DatasetR(training_set = training_set, nb_users = nb_users)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "# print('Train Len')\n",
        "# print(training_set.shape)\n",
        "# print(nb_users)\n",
        "# print(test_set.shape)\n",
        "\n",
        "datasetTest = DatasetR(training_set = test_set, nb_users = nb_users)\n",
        "test_loader = torch.utils.data.DataLoader(datasetTest, batch_size = batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " #Defining a criterion which specifies the metric to minimize. In this case, we want to minimize the MSE (Mean Squared Error)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Defining the algorithm used to minimize the loss function. In this case, we'll use RMSprop\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0DBPxVeVOz9j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "826a629a-34d1-460e-cef8-0347a913daea"
      },
      "source": [
        "# Setting the number of epochs\n",
        "\n",
        "closses = []\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "nb_epoch = 1000\n",
        "\n",
        "# Iterating over each epoch\n",
        "\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "\n",
        "    #sae.train()\n",
        "\n",
        "    # Initializing the train_loss which will be updated\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    # Initializing a counter\n",
        "\n",
        "    s = 0.\n",
        "\n",
        "    # Iterating over each user\n",
        "\n",
        "    #for id_user in range(nb_users):\n",
        "\n",
        "    for batch_idx, (sample) in enumerate(train_loader):\n",
        "\n",
        "        # The input corresponds to the ratings given by the current user for each movie\n",
        "\n",
        "        input = Variable(sample)\n",
        "\n",
        "        target = input.clone()\n",
        "\n",
        "        # We don't consider movies NOT rated by the current user. So we specify a conditional statement\n",
        "\n",
        "        if torch.sum(target.data > 0) > 0:\n",
        "\n",
        "            # We use our SAE to get the output from the \n",
        "\n",
        "            #print('input:  '+ str(input.shape))\n",
        "\n",
        "            output = sae(input)\n",
        "\n",
        "            #print(output.shape)\n",
        "\n",
        "            target.require_grad = False\n",
        "\n",
        "            output[target == 0] = 0\n",
        "\n",
        "            # Defining our loss function, comparing the output with the target\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "\n",
        "            # Computing the gradients necessary to adjust the weights\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Updating the train_loss\n",
        "\n",
        "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
        "\n",
        "            s += 1.\n",
        "\n",
        "            # Updating the weights of the neural network\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "    epoch_loss = train_loss / len(train_loader)\n",
        "    closses.append(epoch_loss)  \n",
        "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))\n",
        "time_end = time.time()\n",
        "print('Stacked-Autoencoder(SAE) Training Time : ' +str(round((time_end-time_start)/60,0))+' Minutes. ')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss: tensor(0.1692)\n",
            "epoch: 2 loss: tensor(0.1651)\n",
            "epoch: 3 loss: tensor(0.1658)\n",
            "epoch: 4 loss: tensor(0.1655)\n",
            "epoch: 5 loss: tensor(0.1638)\n",
            "epoch: 6 loss: tensor(0.1644)\n",
            "epoch: 7 loss: tensor(0.1639)\n",
            "epoch: 8 loss: tensor(0.1639)\n",
            "epoch: 9 loss: tensor(0.1632)\n",
            "epoch: 10 loss: tensor(0.1630)\n",
            "epoch: 11 loss: tensor(0.1618)\n",
            "epoch: 12 loss: tensor(0.1630)\n",
            "epoch: 13 loss: tensor(0.1632)\n",
            "epoch: 14 loss: tensor(0.1623)\n",
            "epoch: 15 loss: tensor(0.1626)\n",
            "epoch: 16 loss: tensor(0.1619)\n",
            "epoch: 17 loss: tensor(0.1610)\n",
            "epoch: 18 loss: tensor(0.1598)\n",
            "epoch: 19 loss: tensor(0.1612)\n",
            "epoch: 20 loss: tensor(0.1596)\n",
            "epoch: 21 loss: tensor(0.1618)\n",
            "epoch: 22 loss: tensor(0.1611)\n",
            "epoch: 23 loss: tensor(0.1605)\n",
            "epoch: 24 loss: tensor(0.1600)\n",
            "epoch: 25 loss: tensor(0.1597)\n",
            "epoch: 26 loss: tensor(0.1606)\n",
            "epoch: 27 loss: tensor(0.1615)\n",
            "epoch: 28 loss: tensor(0.1587)\n",
            "epoch: 29 loss: tensor(0.1597)\n",
            "epoch: 30 loss: tensor(0.1588)\n",
            "epoch: 31 loss: tensor(0.1594)\n",
            "epoch: 32 loss: tensor(0.1576)\n",
            "epoch: 33 loss: tensor(0.1573)\n",
            "epoch: 34 loss: tensor(0.1586)\n",
            "epoch: 35 loss: tensor(0.1591)\n",
            "epoch: 36 loss: tensor(0.1563)\n",
            "epoch: 37 loss: tensor(0.1555)\n",
            "epoch: 38 loss: tensor(0.1569)\n",
            "epoch: 39 loss: tensor(0.1563)\n",
            "epoch: 40 loss: tensor(0.1555)\n",
            "epoch: 41 loss: tensor(0.1562)\n",
            "epoch: 42 loss: tensor(0.1560)\n",
            "epoch: 43 loss: tensor(0.1549)\n",
            "epoch: 44 loss: tensor(0.1530)\n",
            "epoch: 45 loss: tensor(0.1526)\n",
            "epoch: 46 loss: tensor(0.1525)\n",
            "epoch: 47 loss: tensor(0.1516)\n",
            "epoch: 48 loss: tensor(0.1510)\n",
            "epoch: 49 loss: tensor(0.1497)\n",
            "epoch: 50 loss: tensor(0.1508)\n",
            "epoch: 51 loss: tensor(0.1491)\n",
            "epoch: 52 loss: tensor(0.1490)\n",
            "epoch: 53 loss: tensor(0.1474)\n",
            "epoch: 54 loss: tensor(0.1469)\n",
            "epoch: 55 loss: tensor(0.1465)\n",
            "epoch: 56 loss: tensor(0.1453)\n",
            "epoch: 57 loss: tensor(0.1458)\n",
            "epoch: 58 loss: tensor(0.1432)\n",
            "epoch: 59 loss: tensor(0.1423)\n",
            "epoch: 60 loss: tensor(0.1410)\n",
            "epoch: 61 loss: tensor(0.1399)\n",
            "epoch: 62 loss: tensor(0.1393)\n",
            "epoch: 63 loss: tensor(0.1370)\n",
            "epoch: 64 loss: tensor(0.1371)\n",
            "epoch: 65 loss: tensor(0.1371)\n",
            "epoch: 66 loss: tensor(0.1340)\n",
            "epoch: 67 loss: tensor(0.1321)\n",
            "epoch: 68 loss: tensor(0.1310)\n",
            "epoch: 69 loss: tensor(0.1293)\n",
            "epoch: 70 loss: tensor(0.1285)\n",
            "epoch: 71 loss: tensor(0.1281)\n",
            "epoch: 72 loss: tensor(0.1257)\n",
            "epoch: 73 loss: tensor(0.1243)\n",
            "epoch: 74 loss: tensor(0.1221)\n",
            "epoch: 75 loss: tensor(0.1208)\n",
            "epoch: 76 loss: tensor(0.1207)\n",
            "epoch: 77 loss: tensor(0.1175)\n",
            "epoch: 78 loss: tensor(0.1164)\n",
            "epoch: 79 loss: tensor(0.1156)\n",
            "epoch: 80 loss: tensor(0.1143)\n",
            "epoch: 81 loss: tensor(0.1124)\n",
            "epoch: 82 loss: tensor(0.1107)\n",
            "epoch: 83 loss: tensor(0.1095)\n",
            "epoch: 84 loss: tensor(0.1105)\n",
            "epoch: 85 loss: tensor(0.1080)\n",
            "epoch: 86 loss: tensor(0.1080)\n",
            "epoch: 87 loss: tensor(0.1065)\n",
            "epoch: 88 loss: tensor(0.1043)\n",
            "epoch: 89 loss: tensor(0.1027)\n",
            "epoch: 90 loss: tensor(0.1027)\n",
            "epoch: 91 loss: tensor(0.1004)\n",
            "epoch: 92 loss: tensor(0.0996)\n",
            "epoch: 93 loss: tensor(0.0981)\n",
            "epoch: 94 loss: tensor(0.0960)\n",
            "epoch: 95 loss: tensor(0.0965)\n",
            "epoch: 96 loss: tensor(0.0969)\n",
            "epoch: 97 loss: tensor(0.0934)\n",
            "epoch: 98 loss: tensor(0.0935)\n",
            "epoch: 99 loss: tensor(0.0938)\n",
            "epoch: 100 loss: tensor(0.0917)\n",
            "epoch: 101 loss: tensor(0.0906)\n",
            "epoch: 102 loss: tensor(0.0899)\n",
            "epoch: 103 loss: tensor(0.0893)\n",
            "epoch: 104 loss: tensor(0.0881)\n",
            "epoch: 105 loss: tensor(0.0882)\n",
            "epoch: 106 loss: tensor(0.0865)\n",
            "epoch: 107 loss: tensor(0.0867)\n",
            "epoch: 108 loss: tensor(0.0856)\n",
            "epoch: 109 loss: tensor(0.0864)\n",
            "epoch: 110 loss: tensor(0.0844)\n",
            "epoch: 111 loss: tensor(0.0841)\n",
            "epoch: 112 loss: tensor(0.0842)\n",
            "epoch: 113 loss: tensor(0.0826)\n",
            "epoch: 114 loss: tensor(0.0819)\n",
            "epoch: 115 loss: tensor(0.0816)\n",
            "epoch: 116 loss: tensor(0.0804)\n",
            "epoch: 117 loss: tensor(0.0816)\n",
            "epoch: 118 loss: tensor(0.0785)\n",
            "epoch: 119 loss: tensor(0.0797)\n",
            "epoch: 120 loss: tensor(0.0794)\n",
            "epoch: 121 loss: tensor(0.0786)\n",
            "epoch: 122 loss: tensor(0.0789)\n",
            "epoch: 123 loss: tensor(0.0781)\n",
            "epoch: 124 loss: tensor(0.0791)\n",
            "epoch: 125 loss: tensor(0.0771)\n",
            "epoch: 126 loss: tensor(0.0767)\n",
            "epoch: 127 loss: tensor(0.0754)\n",
            "epoch: 128 loss: tensor(0.0757)\n",
            "epoch: 129 loss: tensor(0.0757)\n",
            "epoch: 130 loss: tensor(0.0735)\n",
            "epoch: 131 loss: tensor(0.0738)\n",
            "epoch: 132 loss: tensor(0.0738)\n",
            "epoch: 133 loss: tensor(0.0737)\n",
            "epoch: 134 loss: tensor(0.0739)\n",
            "epoch: 135 loss: tensor(0.0718)\n",
            "epoch: 136 loss: tensor(0.0724)\n",
            "epoch: 137 loss: tensor(0.0725)\n",
            "epoch: 138 loss: tensor(0.0727)\n",
            "epoch: 139 loss: tensor(0.0720)\n",
            "epoch: 140 loss: tensor(0.0702)\n",
            "epoch: 141 loss: tensor(0.0701)\n",
            "epoch: 142 loss: tensor(0.0703)\n",
            "epoch: 143 loss: tensor(0.0697)\n",
            "epoch: 144 loss: tensor(0.0701)\n",
            "epoch: 145 loss: tensor(0.0703)\n",
            "epoch: 146 loss: tensor(0.0694)\n",
            "epoch: 147 loss: tensor(0.0680)\n",
            "epoch: 148 loss: tensor(0.0683)\n",
            "epoch: 149 loss: tensor(0.0674)\n",
            "epoch: 150 loss: tensor(0.0675)\n",
            "epoch: 151 loss: tensor(0.0669)\n",
            "epoch: 152 loss: tensor(0.0672)\n",
            "epoch: 153 loss: tensor(0.0665)\n",
            "epoch: 154 loss: tensor(0.0666)\n",
            "epoch: 155 loss: tensor(0.0676)\n",
            "epoch: 156 loss: tensor(0.0663)\n",
            "epoch: 157 loss: tensor(0.0656)\n",
            "epoch: 158 loss: tensor(0.0655)\n",
            "epoch: 159 loss: tensor(0.0661)\n",
            "epoch: 160 loss: tensor(0.0651)\n",
            "epoch: 161 loss: tensor(0.0645)\n",
            "epoch: 162 loss: tensor(0.0650)\n",
            "epoch: 163 loss: tensor(0.0638)\n",
            "epoch: 164 loss: tensor(0.0637)\n",
            "epoch: 165 loss: tensor(0.0642)\n",
            "epoch: 166 loss: tensor(0.0645)\n",
            "epoch: 167 loss: tensor(0.0635)\n",
            "epoch: 168 loss: tensor(0.0629)\n",
            "epoch: 169 loss: tensor(0.0633)\n",
            "epoch: 170 loss: tensor(0.0638)\n",
            "epoch: 171 loss: tensor(0.0625)\n",
            "epoch: 172 loss: tensor(0.0629)\n",
            "epoch: 173 loss: tensor(0.0628)\n",
            "epoch: 174 loss: tensor(0.0617)\n",
            "epoch: 175 loss: tensor(0.0629)\n",
            "epoch: 176 loss: tensor(0.0623)\n",
            "epoch: 177 loss: tensor(0.0617)\n",
            "epoch: 178 loss: tensor(0.0614)\n",
            "epoch: 179 loss: tensor(0.0610)\n",
            "epoch: 180 loss: tensor(0.0616)\n",
            "epoch: 181 loss: tensor(0.0603)\n",
            "epoch: 182 loss: tensor(0.0611)\n",
            "epoch: 183 loss: tensor(0.0605)\n",
            "epoch: 184 loss: tensor(0.0612)\n",
            "epoch: 185 loss: tensor(0.0606)\n",
            "epoch: 186 loss: tensor(0.0609)\n",
            "epoch: 187 loss: tensor(0.0596)\n",
            "epoch: 188 loss: tensor(0.0603)\n",
            "epoch: 189 loss: tensor(0.0596)\n",
            "epoch: 190 loss: tensor(0.0612)\n",
            "epoch: 191 loss: tensor(0.0588)\n",
            "epoch: 192 loss: tensor(0.0603)\n",
            "epoch: 193 loss: tensor(0.0583)\n",
            "epoch: 194 loss: tensor(0.0596)\n",
            "epoch: 195 loss: tensor(0.0584)\n",
            "epoch: 196 loss: tensor(0.0592)\n",
            "epoch: 197 loss: tensor(0.0587)\n",
            "epoch: 198 loss: tensor(0.0589)\n",
            "epoch: 199 loss: tensor(0.0577)\n",
            "epoch: 200 loss: tensor(0.0582)\n",
            "epoch: 201 loss: tensor(0.0566)\n",
            "epoch: 202 loss: tensor(0.0583)\n",
            "epoch: 203 loss: tensor(0.0574)\n",
            "epoch: 204 loss: tensor(0.0582)\n",
            "epoch: 205 loss: tensor(0.0566)\n",
            "epoch: 206 loss: tensor(0.0576)\n",
            "epoch: 207 loss: tensor(0.0565)\n",
            "epoch: 208 loss: tensor(0.0575)\n",
            "epoch: 209 loss: tensor(0.0581)\n",
            "epoch: 210 loss: tensor(0.0567)\n",
            "epoch: 211 loss: tensor(0.0584)\n",
            "epoch: 212 loss: tensor(0.0581)\n",
            "epoch: 213 loss: tensor(0.0576)\n",
            "epoch: 214 loss: tensor(0.0577)\n",
            "epoch: 215 loss: tensor(0.0565)\n",
            "epoch: 216 loss: tensor(0.0566)\n",
            "epoch: 217 loss: tensor(0.0557)\n",
            "epoch: 218 loss: tensor(0.0565)\n",
            "epoch: 219 loss: tensor(0.0558)\n",
            "epoch: 220 loss: tensor(0.0569)\n",
            "epoch: 221 loss: tensor(0.0566)\n",
            "epoch: 222 loss: tensor(0.0560)\n",
            "epoch: 223 loss: tensor(0.0571)\n",
            "epoch: 224 loss: tensor(0.0560)\n",
            "epoch: 225 loss: tensor(0.0553)\n",
            "epoch: 226 loss: tensor(0.0550)\n",
            "epoch: 227 loss: tensor(0.0551)\n",
            "epoch: 228 loss: tensor(0.0560)\n",
            "epoch: 229 loss: tensor(0.0549)\n",
            "epoch: 230 loss: tensor(0.0561)\n",
            "epoch: 231 loss: tensor(0.0543)\n",
            "epoch: 232 loss: tensor(0.0548)\n",
            "epoch: 233 loss: tensor(0.0545)\n",
            "epoch: 234 loss: tensor(0.0557)\n",
            "epoch: 235 loss: tensor(0.0549)\n",
            "epoch: 236 loss: tensor(0.0543)\n",
            "epoch: 237 loss: tensor(0.0540)\n",
            "epoch: 238 loss: tensor(0.0546)\n",
            "epoch: 239 loss: tensor(0.0541)\n",
            "epoch: 240 loss: tensor(0.0540)\n",
            "epoch: 241 loss: tensor(0.0550)\n",
            "epoch: 242 loss: tensor(0.0535)\n",
            "epoch: 243 loss: tensor(0.0544)\n",
            "epoch: 244 loss: tensor(0.0534)\n",
            "epoch: 245 loss: tensor(0.0529)\n",
            "epoch: 246 loss: tensor(0.0542)\n",
            "epoch: 247 loss: tensor(0.0537)\n",
            "epoch: 248 loss: tensor(0.0544)\n",
            "epoch: 249 loss: tensor(0.0534)\n",
            "epoch: 250 loss: tensor(0.0541)\n",
            "epoch: 251 loss: tensor(0.0536)\n",
            "epoch: 252 loss: tensor(0.0541)\n",
            "epoch: 253 loss: tensor(0.0533)\n",
            "epoch: 254 loss: tensor(0.0542)\n",
            "epoch: 255 loss: tensor(0.0535)\n",
            "epoch: 256 loss: tensor(0.0536)\n",
            "epoch: 257 loss: tensor(0.0532)\n",
            "epoch: 258 loss: tensor(0.0537)\n",
            "epoch: 259 loss: tensor(0.0530)\n",
            "epoch: 260 loss: tensor(0.0529)\n",
            "epoch: 261 loss: tensor(0.0530)\n",
            "epoch: 262 loss: tensor(0.0520)\n",
            "epoch: 263 loss: tensor(0.0529)\n",
            "epoch: 264 loss: tensor(0.0525)\n",
            "epoch: 265 loss: tensor(0.0526)\n",
            "epoch: 266 loss: tensor(0.0526)\n",
            "epoch: 267 loss: tensor(0.0519)\n",
            "epoch: 268 loss: tensor(0.0519)\n",
            "epoch: 269 loss: tensor(0.0539)\n",
            "epoch: 270 loss: tensor(0.0526)\n",
            "epoch: 271 loss: tensor(0.0518)\n",
            "epoch: 272 loss: tensor(0.0525)\n",
            "epoch: 273 loss: tensor(0.0518)\n",
            "epoch: 274 loss: tensor(0.0535)\n",
            "epoch: 275 loss: tensor(0.0515)\n",
            "epoch: 276 loss: tensor(0.0520)\n",
            "epoch: 277 loss: tensor(0.0520)\n",
            "epoch: 278 loss: tensor(0.0517)\n",
            "epoch: 279 loss: tensor(0.0511)\n",
            "epoch: 280 loss: tensor(0.0523)\n",
            "epoch: 281 loss: tensor(0.0522)\n",
            "epoch: 282 loss: tensor(0.0527)\n",
            "epoch: 283 loss: tensor(0.0539)\n",
            "epoch: 284 loss: tensor(0.0519)\n",
            "epoch: 285 loss: tensor(0.0513)\n",
            "epoch: 286 loss: tensor(0.0512)\n",
            "epoch: 287 loss: tensor(0.0516)\n",
            "epoch: 288 loss: tensor(0.0520)\n",
            "epoch: 289 loss: tensor(0.0515)\n",
            "epoch: 290 loss: tensor(0.0511)\n",
            "epoch: 291 loss: tensor(0.0512)\n",
            "epoch: 292 loss: tensor(0.0519)\n",
            "epoch: 293 loss: tensor(0.0514)\n",
            "epoch: 294 loss: tensor(0.0515)\n",
            "epoch: 295 loss: tensor(0.0515)\n",
            "epoch: 296 loss: tensor(0.0514)\n",
            "epoch: 297 loss: tensor(0.0510)\n",
            "epoch: 298 loss: tensor(0.0513)\n",
            "epoch: 299 loss: tensor(0.0509)\n",
            "epoch: 300 loss: tensor(0.0520)\n",
            "epoch: 301 loss: tensor(0.0507)\n",
            "epoch: 302 loss: tensor(0.0510)\n",
            "epoch: 303 loss: tensor(0.0509)\n",
            "epoch: 304 loss: tensor(0.0513)\n",
            "epoch: 305 loss: tensor(0.0528)\n",
            "epoch: 306 loss: tensor(0.0525)\n",
            "epoch: 307 loss: tensor(0.0523)\n",
            "epoch: 308 loss: tensor(0.0512)\n",
            "epoch: 309 loss: tensor(0.0525)\n",
            "epoch: 310 loss: tensor(0.0510)\n",
            "epoch: 311 loss: tensor(0.0511)\n",
            "epoch: 312 loss: tensor(0.0501)\n",
            "epoch: 313 loss: tensor(0.0513)\n",
            "epoch: 314 loss: tensor(0.0501)\n",
            "epoch: 315 loss: tensor(0.0518)\n",
            "epoch: 316 loss: tensor(0.0504)\n",
            "epoch: 317 loss: tensor(0.0500)\n",
            "epoch: 318 loss: tensor(0.0503)\n",
            "epoch: 319 loss: tensor(0.0505)\n",
            "epoch: 320 loss: tensor(0.0501)\n",
            "epoch: 321 loss: tensor(0.0514)\n",
            "epoch: 322 loss: tensor(0.0512)\n",
            "epoch: 323 loss: tensor(0.0504)\n",
            "epoch: 324 loss: tensor(0.0513)\n",
            "epoch: 325 loss: tensor(0.0505)\n",
            "epoch: 326 loss: tensor(0.0509)\n",
            "epoch: 327 loss: tensor(0.0505)\n",
            "epoch: 328 loss: tensor(0.0508)\n",
            "epoch: 329 loss: tensor(0.0494)\n",
            "epoch: 330 loss: tensor(0.0503)\n",
            "epoch: 331 loss: tensor(0.0499)\n",
            "epoch: 332 loss: tensor(0.0498)\n",
            "epoch: 333 loss: tensor(0.0497)\n",
            "epoch: 334 loss: tensor(0.0507)\n",
            "epoch: 335 loss: tensor(0.0491)\n",
            "epoch: 336 loss: tensor(0.0502)\n",
            "epoch: 337 loss: tensor(0.0488)\n",
            "epoch: 338 loss: tensor(0.0503)\n",
            "epoch: 339 loss: tensor(0.0494)\n",
            "epoch: 340 loss: tensor(0.0507)\n",
            "epoch: 341 loss: tensor(0.0506)\n",
            "epoch: 342 loss: tensor(0.0498)\n",
            "epoch: 343 loss: tensor(0.0505)\n",
            "epoch: 344 loss: tensor(0.0509)\n",
            "epoch: 345 loss: tensor(0.0504)\n",
            "epoch: 346 loss: tensor(0.0508)\n",
            "epoch: 347 loss: tensor(0.0501)\n",
            "epoch: 348 loss: tensor(0.0502)\n",
            "epoch: 349 loss: tensor(0.0491)\n",
            "epoch: 350 loss: tensor(0.0494)\n",
            "epoch: 351 loss: tensor(0.0490)\n",
            "epoch: 352 loss: tensor(0.0490)\n",
            "epoch: 353 loss: tensor(0.0501)\n",
            "epoch: 354 loss: tensor(0.0495)\n",
            "epoch: 355 loss: tensor(0.0494)\n",
            "epoch: 356 loss: tensor(0.0495)\n",
            "epoch: 357 loss: tensor(0.0496)\n",
            "epoch: 358 loss: tensor(0.0491)\n",
            "epoch: 359 loss: tensor(0.0500)\n",
            "epoch: 360 loss: tensor(0.0491)\n",
            "epoch: 361 loss: tensor(0.0495)\n",
            "epoch: 362 loss: tensor(0.0491)\n",
            "epoch: 363 loss: tensor(0.0488)\n",
            "epoch: 364 loss: tensor(0.0484)\n",
            "epoch: 365 loss: tensor(0.0478)\n",
            "epoch: 366 loss: tensor(0.0489)\n",
            "epoch: 367 loss: tensor(0.0494)\n",
            "epoch: 368 loss: tensor(0.0489)\n",
            "epoch: 369 loss: tensor(0.0491)\n",
            "epoch: 370 loss: tensor(0.0493)\n",
            "epoch: 371 loss: tensor(0.0495)\n",
            "epoch: 372 loss: tensor(0.0504)\n",
            "epoch: 373 loss: tensor(0.0490)\n",
            "epoch: 374 loss: tensor(0.0507)\n",
            "epoch: 375 loss: tensor(0.0489)\n",
            "epoch: 376 loss: tensor(0.0496)\n",
            "epoch: 377 loss: tensor(0.0485)\n",
            "epoch: 378 loss: tensor(0.0491)\n",
            "epoch: 379 loss: tensor(0.0494)\n",
            "epoch: 380 loss: tensor(0.0494)\n",
            "epoch: 381 loss: tensor(0.0487)\n",
            "epoch: 382 loss: tensor(0.0496)\n",
            "epoch: 383 loss: tensor(0.0486)\n",
            "epoch: 384 loss: tensor(0.0489)\n",
            "epoch: 385 loss: tensor(0.0491)\n",
            "epoch: 386 loss: tensor(0.0482)\n",
            "epoch: 387 loss: tensor(0.0493)\n",
            "epoch: 388 loss: tensor(0.0491)\n",
            "epoch: 389 loss: tensor(0.0496)\n",
            "epoch: 390 loss: tensor(0.0487)\n",
            "epoch: 391 loss: tensor(0.0484)\n",
            "epoch: 392 loss: tensor(0.0499)\n",
            "epoch: 393 loss: tensor(0.0487)\n",
            "epoch: 394 loss: tensor(0.0490)\n",
            "epoch: 395 loss: tensor(0.0489)\n",
            "epoch: 396 loss: tensor(0.0488)\n",
            "epoch: 397 loss: tensor(0.0482)\n",
            "epoch: 398 loss: tensor(0.0484)\n",
            "epoch: 399 loss: tensor(0.0478)\n",
            "epoch: 400 loss: tensor(0.0480)\n",
            "epoch: 401 loss: tensor(0.0494)\n",
            "epoch: 402 loss: tensor(0.0485)\n",
            "epoch: 403 loss: tensor(0.0490)\n",
            "epoch: 404 loss: tensor(0.0485)\n",
            "epoch: 405 loss: tensor(0.0487)\n",
            "epoch: 406 loss: tensor(0.0485)\n",
            "epoch: 407 loss: tensor(0.0483)\n",
            "epoch: 408 loss: tensor(0.0493)\n",
            "epoch: 409 loss: tensor(0.0480)\n",
            "epoch: 410 loss: tensor(0.0484)\n",
            "epoch: 411 loss: tensor(0.0484)\n",
            "epoch: 412 loss: tensor(0.0483)\n",
            "epoch: 413 loss: tensor(0.0485)\n",
            "epoch: 414 loss: tensor(0.0480)\n",
            "epoch: 415 loss: tensor(0.0476)\n",
            "epoch: 416 loss: tensor(0.0480)\n",
            "epoch: 417 loss: tensor(0.0477)\n",
            "epoch: 418 loss: tensor(0.0480)\n",
            "epoch: 419 loss: tensor(0.0478)\n",
            "epoch: 420 loss: tensor(0.0477)\n",
            "epoch: 421 loss: tensor(0.0476)\n",
            "epoch: 422 loss: tensor(0.0480)\n",
            "epoch: 423 loss: tensor(0.0478)\n",
            "epoch: 424 loss: tensor(0.0474)\n",
            "epoch: 425 loss: tensor(0.0490)\n",
            "epoch: 426 loss: tensor(0.0469)\n",
            "epoch: 427 loss: tensor(0.0490)\n",
            "epoch: 428 loss: tensor(0.0483)\n",
            "epoch: 429 loss: tensor(0.0477)\n",
            "epoch: 430 loss: tensor(0.0480)\n",
            "epoch: 431 loss: tensor(0.0475)\n",
            "epoch: 432 loss: tensor(0.0479)\n",
            "epoch: 433 loss: tensor(0.0477)\n",
            "epoch: 434 loss: tensor(0.0483)\n",
            "epoch: 435 loss: tensor(0.0483)\n",
            "epoch: 436 loss: tensor(0.0485)\n",
            "epoch: 437 loss: tensor(0.0474)\n",
            "epoch: 438 loss: tensor(0.0487)\n",
            "epoch: 439 loss: tensor(0.0478)\n",
            "epoch: 440 loss: tensor(0.0479)\n",
            "epoch: 441 loss: tensor(0.0481)\n",
            "epoch: 442 loss: tensor(0.0487)\n",
            "epoch: 443 loss: tensor(0.0475)\n",
            "epoch: 444 loss: tensor(0.0488)\n",
            "epoch: 445 loss: tensor(0.0486)\n",
            "epoch: 446 loss: tensor(0.0481)\n",
            "epoch: 447 loss: tensor(0.0484)\n",
            "epoch: 448 loss: tensor(0.0469)\n",
            "epoch: 449 loss: tensor(0.0484)\n",
            "epoch: 450 loss: tensor(0.0477)\n",
            "epoch: 451 loss: tensor(0.0480)\n",
            "epoch: 452 loss: tensor(0.0474)\n",
            "epoch: 453 loss: tensor(0.0491)\n",
            "epoch: 454 loss: tensor(0.0473)\n",
            "epoch: 455 loss: tensor(0.0473)\n",
            "epoch: 456 loss: tensor(0.0478)\n",
            "epoch: 457 loss: tensor(0.0477)\n",
            "epoch: 458 loss: tensor(0.0467)\n",
            "epoch: 459 loss: tensor(0.0476)\n",
            "epoch: 460 loss: tensor(0.0474)\n",
            "epoch: 461 loss: tensor(0.0482)\n",
            "epoch: 462 loss: tensor(0.0479)\n",
            "epoch: 463 loss: tensor(0.0468)\n",
            "epoch: 464 loss: tensor(0.0480)\n",
            "epoch: 465 loss: tensor(0.0463)\n",
            "epoch: 466 loss: tensor(0.0481)\n",
            "epoch: 467 loss: tensor(0.0466)\n",
            "epoch: 468 loss: tensor(0.0473)\n",
            "epoch: 469 loss: tensor(0.0460)\n",
            "epoch: 470 loss: tensor(0.0480)\n",
            "epoch: 471 loss: tensor(0.0471)\n",
            "epoch: 472 loss: tensor(0.0470)\n",
            "epoch: 473 loss: tensor(0.0465)\n",
            "epoch: 474 loss: tensor(0.0465)\n",
            "epoch: 475 loss: tensor(0.0466)\n",
            "epoch: 476 loss: tensor(0.0472)\n",
            "epoch: 477 loss: tensor(0.0471)\n",
            "epoch: 478 loss: tensor(0.0469)\n",
            "epoch: 479 loss: tensor(0.0464)\n",
            "epoch: 480 loss: tensor(0.0469)\n",
            "epoch: 481 loss: tensor(0.0465)\n",
            "epoch: 482 loss: tensor(0.0471)\n",
            "epoch: 483 loss: tensor(0.0477)\n",
            "epoch: 484 loss: tensor(0.0480)\n",
            "epoch: 485 loss: tensor(0.0484)\n",
            "epoch: 486 loss: tensor(0.0482)\n",
            "epoch: 487 loss: tensor(0.0483)\n",
            "epoch: 488 loss: tensor(0.0481)\n",
            "epoch: 489 loss: tensor(0.0481)\n",
            "epoch: 490 loss: tensor(0.0473)\n",
            "epoch: 491 loss: tensor(0.0485)\n",
            "epoch: 492 loss: tensor(0.0477)\n",
            "epoch: 493 loss: tensor(0.0479)\n",
            "epoch: 494 loss: tensor(0.0482)\n",
            "epoch: 495 loss: tensor(0.0470)\n",
            "epoch: 496 loss: tensor(0.0478)\n",
            "epoch: 497 loss: tensor(0.0474)\n",
            "epoch: 498 loss: tensor(0.0469)\n",
            "epoch: 499 loss: tensor(0.0479)\n",
            "epoch: 500 loss: tensor(0.0472)\n",
            "epoch: 501 loss: tensor(0.0472)\n",
            "epoch: 502 loss: tensor(0.0470)\n",
            "epoch: 503 loss: tensor(0.0464)\n",
            "epoch: 504 loss: tensor(0.0463)\n",
            "epoch: 505 loss: tensor(0.0473)\n",
            "epoch: 506 loss: tensor(0.0469)\n",
            "epoch: 507 loss: tensor(0.0469)\n",
            "epoch: 508 loss: tensor(0.0465)\n",
            "epoch: 509 loss: tensor(0.0467)\n",
            "epoch: 510 loss: tensor(0.0461)\n",
            "epoch: 511 loss: tensor(0.0461)\n",
            "epoch: 512 loss: tensor(0.0463)\n",
            "epoch: 513 loss: tensor(0.0461)\n",
            "epoch: 514 loss: tensor(0.0460)\n",
            "epoch: 515 loss: tensor(0.0463)\n",
            "epoch: 516 loss: tensor(0.0462)\n",
            "epoch: 517 loss: tensor(0.0464)\n",
            "epoch: 518 loss: tensor(0.0465)\n",
            "epoch: 519 loss: tensor(0.0458)\n",
            "epoch: 520 loss: tensor(0.0470)\n",
            "epoch: 521 loss: tensor(0.0466)\n",
            "epoch: 522 loss: tensor(0.0467)\n",
            "epoch: 523 loss: tensor(0.0466)\n",
            "epoch: 524 loss: tensor(0.0466)\n",
            "epoch: 525 loss: tensor(0.0460)\n",
            "epoch: 526 loss: tensor(0.0466)\n",
            "epoch: 527 loss: tensor(0.0470)\n",
            "epoch: 528 loss: tensor(0.0475)\n",
            "epoch: 529 loss: tensor(0.0469)\n",
            "epoch: 530 loss: tensor(0.0466)\n",
            "epoch: 531 loss: tensor(0.0463)\n",
            "epoch: 532 loss: tensor(0.0460)\n",
            "epoch: 533 loss: tensor(0.0468)\n",
            "epoch: 534 loss: tensor(0.0466)\n",
            "epoch: 535 loss: tensor(0.0461)\n",
            "epoch: 536 loss: tensor(0.0474)\n",
            "epoch: 537 loss: tensor(0.0461)\n",
            "epoch: 538 loss: tensor(0.0471)\n",
            "epoch: 539 loss: tensor(0.0456)\n",
            "epoch: 540 loss: tensor(0.0465)\n",
            "epoch: 541 loss: tensor(0.0455)\n",
            "epoch: 542 loss: tensor(0.0464)\n",
            "epoch: 543 loss: tensor(0.0463)\n",
            "epoch: 544 loss: tensor(0.0467)\n",
            "epoch: 545 loss: tensor(0.0460)\n",
            "epoch: 546 loss: tensor(0.0463)\n",
            "epoch: 547 loss: tensor(0.0462)\n",
            "epoch: 548 loss: tensor(0.0457)\n",
            "epoch: 549 loss: tensor(0.0459)\n",
            "epoch: 550 loss: tensor(0.0457)\n",
            "epoch: 551 loss: tensor(0.0458)\n",
            "epoch: 552 loss: tensor(0.0455)\n",
            "epoch: 553 loss: tensor(0.0459)\n",
            "epoch: 554 loss: tensor(0.0458)\n",
            "epoch: 555 loss: tensor(0.0463)\n",
            "epoch: 556 loss: tensor(0.0463)\n",
            "epoch: 557 loss: tensor(0.0459)\n",
            "epoch: 558 loss: tensor(0.0468)\n",
            "epoch: 559 loss: tensor(0.0452)\n",
            "epoch: 560 loss: tensor(0.0465)\n",
            "epoch: 561 loss: tensor(0.0456)\n",
            "epoch: 562 loss: tensor(0.0457)\n",
            "epoch: 563 loss: tensor(0.0456)\n",
            "epoch: 564 loss: tensor(0.0458)\n",
            "epoch: 565 loss: tensor(0.0458)\n",
            "epoch: 566 loss: tensor(0.0462)\n",
            "epoch: 567 loss: tensor(0.0458)\n",
            "epoch: 568 loss: tensor(0.0458)\n",
            "epoch: 569 loss: tensor(0.0455)\n",
            "epoch: 570 loss: tensor(0.0461)\n",
            "epoch: 571 loss: tensor(0.0464)\n",
            "epoch: 572 loss: tensor(0.0463)\n",
            "epoch: 573 loss: tensor(0.0466)\n",
            "epoch: 574 loss: tensor(0.0458)\n",
            "epoch: 575 loss: tensor(0.0468)\n",
            "epoch: 576 loss: tensor(0.0458)\n",
            "epoch: 577 loss: tensor(0.0457)\n",
            "epoch: 578 loss: tensor(0.0470)\n",
            "epoch: 579 loss: tensor(0.0466)\n",
            "epoch: 580 loss: tensor(0.0467)\n",
            "epoch: 581 loss: tensor(0.0460)\n",
            "epoch: 582 loss: tensor(0.0468)\n",
            "epoch: 583 loss: tensor(0.0461)\n",
            "epoch: 584 loss: tensor(0.0463)\n",
            "epoch: 585 loss: tensor(0.0459)\n",
            "epoch: 586 loss: tensor(0.0462)\n",
            "epoch: 587 loss: tensor(0.0452)\n",
            "epoch: 588 loss: tensor(0.0458)\n",
            "epoch: 589 loss: tensor(0.0447)\n",
            "epoch: 590 loss: tensor(0.0454)\n",
            "epoch: 591 loss: tensor(0.0449)\n",
            "epoch: 592 loss: tensor(0.0463)\n",
            "epoch: 593 loss: tensor(0.0451)\n",
            "epoch: 594 loss: tensor(0.0462)\n",
            "epoch: 595 loss: tensor(0.0466)\n",
            "epoch: 596 loss: tensor(0.0453)\n",
            "epoch: 597 loss: tensor(0.0455)\n",
            "epoch: 598 loss: tensor(0.0454)\n",
            "epoch: 599 loss: tensor(0.0458)\n",
            "epoch: 600 loss: tensor(0.0457)\n",
            "epoch: 601 loss: tensor(0.0458)\n",
            "epoch: 602 loss: tensor(0.0462)\n",
            "epoch: 603 loss: tensor(0.0455)\n",
            "epoch: 604 loss: tensor(0.0465)\n",
            "epoch: 605 loss: tensor(0.0449)\n",
            "epoch: 606 loss: tensor(0.0464)\n",
            "epoch: 607 loss: tensor(0.0448)\n",
            "epoch: 608 loss: tensor(0.0463)\n",
            "epoch: 609 loss: tensor(0.0454)\n",
            "epoch: 610 loss: tensor(0.0448)\n",
            "epoch: 611 loss: tensor(0.0451)\n",
            "epoch: 612 loss: tensor(0.0457)\n",
            "epoch: 613 loss: tensor(0.0452)\n",
            "epoch: 614 loss: tensor(0.0453)\n",
            "epoch: 615 loss: tensor(0.0458)\n",
            "epoch: 616 loss: tensor(0.0464)\n",
            "epoch: 617 loss: tensor(0.0459)\n",
            "epoch: 618 loss: tensor(0.0459)\n",
            "epoch: 619 loss: tensor(0.0461)\n",
            "epoch: 620 loss: tensor(0.0456)\n",
            "epoch: 621 loss: tensor(0.0458)\n",
            "epoch: 622 loss: tensor(0.0453)\n",
            "epoch: 623 loss: tensor(0.0459)\n",
            "epoch: 624 loss: tensor(0.0464)\n",
            "epoch: 625 loss: tensor(0.0462)\n",
            "epoch: 626 loss: tensor(0.0461)\n",
            "epoch: 627 loss: tensor(0.0450)\n",
            "epoch: 628 loss: tensor(0.0461)\n",
            "epoch: 629 loss: tensor(0.0453)\n",
            "epoch: 630 loss: tensor(0.0459)\n",
            "epoch: 631 loss: tensor(0.0450)\n",
            "epoch: 632 loss: tensor(0.0457)\n",
            "epoch: 633 loss: tensor(0.0444)\n",
            "epoch: 634 loss: tensor(0.0459)\n",
            "epoch: 635 loss: tensor(0.0450)\n",
            "epoch: 636 loss: tensor(0.0452)\n",
            "epoch: 637 loss: tensor(0.0455)\n",
            "epoch: 638 loss: tensor(0.0457)\n",
            "epoch: 639 loss: tensor(0.0451)\n",
            "epoch: 640 loss: tensor(0.0457)\n",
            "epoch: 641 loss: tensor(0.0451)\n",
            "epoch: 642 loss: tensor(0.0460)\n",
            "epoch: 643 loss: tensor(0.0455)\n",
            "epoch: 644 loss: tensor(0.0459)\n",
            "epoch: 645 loss: tensor(0.0459)\n",
            "epoch: 646 loss: tensor(0.0458)\n",
            "epoch: 647 loss: tensor(0.0462)\n",
            "epoch: 648 loss: tensor(0.0462)\n",
            "epoch: 649 loss: tensor(0.0450)\n",
            "epoch: 650 loss: tensor(0.0462)\n",
            "epoch: 651 loss: tensor(0.0443)\n",
            "epoch: 652 loss: tensor(0.0455)\n",
            "epoch: 653 loss: tensor(0.0458)\n",
            "epoch: 654 loss: tensor(0.0458)\n",
            "epoch: 655 loss: tensor(0.0452)\n",
            "epoch: 656 loss: tensor(0.0455)\n",
            "epoch: 657 loss: tensor(0.0450)\n",
            "epoch: 658 loss: tensor(0.0457)\n",
            "epoch: 659 loss: tensor(0.0457)\n",
            "epoch: 660 loss: tensor(0.0453)\n",
            "epoch: 661 loss: tensor(0.0460)\n",
            "epoch: 662 loss: tensor(0.0452)\n",
            "epoch: 663 loss: tensor(0.0455)\n",
            "epoch: 664 loss: tensor(0.0450)\n",
            "epoch: 665 loss: tensor(0.0462)\n",
            "epoch: 666 loss: tensor(0.0447)\n",
            "epoch: 667 loss: tensor(0.0457)\n",
            "epoch: 668 loss: tensor(0.0451)\n",
            "epoch: 669 loss: tensor(0.0455)\n",
            "epoch: 670 loss: tensor(0.0457)\n",
            "epoch: 671 loss: tensor(0.0453)\n",
            "epoch: 672 loss: tensor(0.0464)\n",
            "epoch: 673 loss: tensor(0.0453)\n",
            "epoch: 674 loss: tensor(0.0461)\n",
            "epoch: 675 loss: tensor(0.0444)\n",
            "epoch: 676 loss: tensor(0.0458)\n",
            "epoch: 677 loss: tensor(0.0452)\n",
            "epoch: 678 loss: tensor(0.0450)\n",
            "epoch: 679 loss: tensor(0.0445)\n",
            "epoch: 680 loss: tensor(0.0453)\n",
            "epoch: 681 loss: tensor(0.0451)\n",
            "epoch: 682 loss: tensor(0.0449)\n",
            "epoch: 683 loss: tensor(0.0442)\n",
            "epoch: 684 loss: tensor(0.0452)\n",
            "epoch: 685 loss: tensor(0.0453)\n",
            "epoch: 686 loss: tensor(0.0453)\n",
            "epoch: 687 loss: tensor(0.0450)\n",
            "epoch: 688 loss: tensor(0.0451)\n",
            "epoch: 689 loss: tensor(0.0457)\n",
            "epoch: 690 loss: tensor(0.0441)\n",
            "epoch: 691 loss: tensor(0.0454)\n",
            "epoch: 692 loss: tensor(0.0448)\n",
            "epoch: 693 loss: tensor(0.0456)\n",
            "epoch: 694 loss: tensor(0.0452)\n",
            "epoch: 695 loss: tensor(0.0462)\n",
            "epoch: 696 loss: tensor(0.0451)\n",
            "epoch: 697 loss: tensor(0.0455)\n",
            "epoch: 698 loss: tensor(0.0454)\n",
            "epoch: 699 loss: tensor(0.0456)\n",
            "epoch: 700 loss: tensor(0.0459)\n",
            "epoch: 701 loss: tensor(0.0449)\n",
            "epoch: 702 loss: tensor(0.0454)\n",
            "epoch: 703 loss: tensor(0.0452)\n",
            "epoch: 704 loss: tensor(0.0452)\n",
            "epoch: 705 loss: tensor(0.0456)\n",
            "epoch: 706 loss: tensor(0.0448)\n",
            "epoch: 707 loss: tensor(0.0451)\n",
            "epoch: 708 loss: tensor(0.0450)\n",
            "epoch: 709 loss: tensor(0.0453)\n",
            "epoch: 710 loss: tensor(0.0450)\n",
            "epoch: 711 loss: tensor(0.0457)\n",
            "epoch: 712 loss: tensor(0.0445)\n",
            "epoch: 713 loss: tensor(0.0450)\n",
            "epoch: 714 loss: tensor(0.0446)\n",
            "epoch: 715 loss: tensor(0.0452)\n",
            "epoch: 716 loss: tensor(0.0450)\n",
            "epoch: 717 loss: tensor(0.0454)\n",
            "epoch: 718 loss: tensor(0.0451)\n",
            "epoch: 719 loss: tensor(0.0456)\n",
            "epoch: 720 loss: tensor(0.0457)\n",
            "epoch: 721 loss: tensor(0.0443)\n",
            "epoch: 722 loss: tensor(0.0460)\n",
            "epoch: 723 loss: tensor(0.0444)\n",
            "epoch: 724 loss: tensor(0.0459)\n",
            "epoch: 725 loss: tensor(0.0443)\n",
            "epoch: 726 loss: tensor(0.0452)\n",
            "epoch: 727 loss: tensor(0.0445)\n",
            "epoch: 728 loss: tensor(0.0452)\n",
            "epoch: 729 loss: tensor(0.0445)\n",
            "epoch: 730 loss: tensor(0.0451)\n",
            "epoch: 731 loss: tensor(0.0448)\n",
            "epoch: 732 loss: tensor(0.0451)\n",
            "epoch: 733 loss: tensor(0.0450)\n",
            "epoch: 734 loss: tensor(0.0451)\n",
            "epoch: 735 loss: tensor(0.0452)\n",
            "epoch: 736 loss: tensor(0.0458)\n",
            "epoch: 737 loss: tensor(0.0451)\n",
            "epoch: 738 loss: tensor(0.0452)\n",
            "epoch: 739 loss: tensor(0.0457)\n",
            "epoch: 740 loss: tensor(0.0444)\n",
            "epoch: 741 loss: tensor(0.0451)\n",
            "epoch: 742 loss: tensor(0.0451)\n",
            "epoch: 743 loss: tensor(0.0451)\n",
            "epoch: 744 loss: tensor(0.0451)\n",
            "epoch: 745 loss: tensor(0.0452)\n",
            "epoch: 746 loss: tensor(0.0454)\n",
            "epoch: 747 loss: tensor(0.0449)\n",
            "epoch: 748 loss: tensor(0.0450)\n",
            "epoch: 749 loss: tensor(0.0443)\n",
            "epoch: 750 loss: tensor(0.0450)\n",
            "epoch: 751 loss: tensor(0.0445)\n",
            "epoch: 752 loss: tensor(0.0452)\n",
            "epoch: 753 loss: tensor(0.0444)\n",
            "epoch: 754 loss: tensor(0.0453)\n",
            "epoch: 755 loss: tensor(0.0447)\n",
            "epoch: 756 loss: tensor(0.0456)\n",
            "epoch: 757 loss: tensor(0.0450)\n",
            "epoch: 758 loss: tensor(0.0451)\n",
            "epoch: 759 loss: tensor(0.0449)\n",
            "epoch: 760 loss: tensor(0.0449)\n",
            "epoch: 761 loss: tensor(0.0445)\n",
            "epoch: 762 loss: tensor(0.0445)\n",
            "epoch: 763 loss: tensor(0.0447)\n",
            "epoch: 764 loss: tensor(0.0439)\n",
            "epoch: 765 loss: tensor(0.0461)\n",
            "epoch: 766 loss: tensor(0.0444)\n",
            "epoch: 767 loss: tensor(0.0455)\n",
            "epoch: 768 loss: tensor(0.0452)\n",
            "epoch: 769 loss: tensor(0.0457)\n",
            "epoch: 770 loss: tensor(0.0450)\n",
            "epoch: 771 loss: tensor(0.0446)\n",
            "epoch: 772 loss: tensor(0.0453)\n",
            "epoch: 773 loss: tensor(0.0445)\n",
            "epoch: 774 loss: tensor(0.0451)\n",
            "epoch: 775 loss: tensor(0.0444)\n",
            "epoch: 776 loss: tensor(0.0454)\n",
            "epoch: 777 loss: tensor(0.0448)\n",
            "epoch: 778 loss: tensor(0.0459)\n",
            "epoch: 779 loss: tensor(0.0441)\n",
            "epoch: 780 loss: tensor(0.0454)\n",
            "epoch: 781 loss: tensor(0.0443)\n",
            "epoch: 782 loss: tensor(0.0452)\n",
            "epoch: 783 loss: tensor(0.0446)\n",
            "epoch: 784 loss: tensor(0.0457)\n",
            "epoch: 785 loss: tensor(0.0447)\n",
            "epoch: 786 loss: tensor(0.0453)\n",
            "epoch: 787 loss: tensor(0.0454)\n",
            "epoch: 788 loss: tensor(0.0453)\n",
            "epoch: 789 loss: tensor(0.0451)\n",
            "epoch: 790 loss: tensor(0.0448)\n",
            "epoch: 791 loss: tensor(0.0446)\n",
            "epoch: 792 loss: tensor(0.0443)\n",
            "epoch: 793 loss: tensor(0.0450)\n",
            "epoch: 794 loss: tensor(0.0445)\n",
            "epoch: 795 loss: tensor(0.0454)\n",
            "epoch: 796 loss: tensor(0.0450)\n",
            "epoch: 797 loss: tensor(0.0456)\n",
            "epoch: 798 loss: tensor(0.0451)\n",
            "epoch: 799 loss: tensor(0.0448)\n",
            "epoch: 800 loss: tensor(0.0452)\n",
            "epoch: 801 loss: tensor(0.0453)\n",
            "epoch: 802 loss: tensor(0.0456)\n",
            "epoch: 803 loss: tensor(0.0442)\n",
            "epoch: 804 loss: tensor(0.0451)\n",
            "epoch: 805 loss: tensor(0.0443)\n",
            "epoch: 806 loss: tensor(0.0454)\n",
            "epoch: 807 loss: tensor(0.0446)\n",
            "epoch: 808 loss: tensor(0.0450)\n",
            "epoch: 809 loss: tensor(0.0446)\n",
            "epoch: 810 loss: tensor(0.0450)\n",
            "epoch: 811 loss: tensor(0.0444)\n",
            "epoch: 812 loss: tensor(0.0448)\n",
            "epoch: 813 loss: tensor(0.0442)\n",
            "epoch: 814 loss: tensor(0.0450)\n",
            "epoch: 815 loss: tensor(0.0441)\n",
            "epoch: 816 loss: tensor(0.0452)\n",
            "epoch: 817 loss: tensor(0.0447)\n",
            "epoch: 818 loss: tensor(0.0452)\n",
            "epoch: 819 loss: tensor(0.0445)\n",
            "epoch: 820 loss: tensor(0.0446)\n",
            "epoch: 821 loss: tensor(0.0451)\n",
            "epoch: 822 loss: tensor(0.0444)\n",
            "epoch: 823 loss: tensor(0.0448)\n",
            "epoch: 824 loss: tensor(0.0447)\n",
            "epoch: 825 loss: tensor(0.0449)\n",
            "epoch: 826 loss: tensor(0.0443)\n",
            "epoch: 827 loss: tensor(0.0449)\n",
            "epoch: 828 loss: tensor(0.0447)\n",
            "epoch: 829 loss: tensor(0.0445)\n",
            "epoch: 830 loss: tensor(0.0449)\n",
            "epoch: 831 loss: tensor(0.0445)\n",
            "epoch: 832 loss: tensor(0.0450)\n",
            "epoch: 833 loss: tensor(0.0443)\n",
            "epoch: 834 loss: tensor(0.0458)\n",
            "epoch: 835 loss: tensor(0.0448)\n",
            "epoch: 836 loss: tensor(0.0453)\n",
            "epoch: 837 loss: tensor(0.0441)\n",
            "epoch: 838 loss: tensor(0.0451)\n",
            "epoch: 839 loss: tensor(0.0446)\n",
            "epoch: 840 loss: tensor(0.0456)\n",
            "epoch: 841 loss: tensor(0.0443)\n",
            "epoch: 842 loss: tensor(0.0454)\n",
            "epoch: 843 loss: tensor(0.0448)\n",
            "epoch: 844 loss: tensor(0.0444)\n",
            "epoch: 845 loss: tensor(0.0459)\n",
            "epoch: 846 loss: tensor(0.0441)\n",
            "epoch: 847 loss: tensor(0.0451)\n",
            "epoch: 848 loss: tensor(0.0435)\n",
            "epoch: 849 loss: tensor(0.0449)\n",
            "epoch: 850 loss: tensor(0.0445)\n",
            "epoch: 851 loss: tensor(0.0445)\n",
            "epoch: 852 loss: tensor(0.0439)\n",
            "epoch: 853 loss: tensor(0.0446)\n",
            "epoch: 854 loss: tensor(0.0448)\n",
            "epoch: 855 loss: tensor(0.0443)\n",
            "epoch: 856 loss: tensor(0.0444)\n",
            "epoch: 857 loss: tensor(0.0444)\n",
            "epoch: 858 loss: tensor(0.0440)\n",
            "epoch: 859 loss: tensor(0.0445)\n",
            "epoch: 860 loss: tensor(0.0450)\n",
            "epoch: 861 loss: tensor(0.0443)\n",
            "epoch: 862 loss: tensor(0.0446)\n",
            "epoch: 863 loss: tensor(0.0441)\n",
            "epoch: 864 loss: tensor(0.0450)\n",
            "epoch: 865 loss: tensor(0.0444)\n",
            "epoch: 866 loss: tensor(0.0454)\n",
            "epoch: 867 loss: tensor(0.0443)\n",
            "epoch: 868 loss: tensor(0.0448)\n",
            "epoch: 869 loss: tensor(0.0437)\n",
            "epoch: 870 loss: tensor(0.0446)\n",
            "epoch: 871 loss: tensor(0.0437)\n",
            "epoch: 872 loss: tensor(0.0453)\n",
            "epoch: 873 loss: tensor(0.0446)\n",
            "epoch: 874 loss: tensor(0.0448)\n",
            "epoch: 875 loss: tensor(0.0449)\n",
            "epoch: 876 loss: tensor(0.0447)\n",
            "epoch: 877 loss: tensor(0.0447)\n",
            "epoch: 878 loss: tensor(0.0447)\n",
            "epoch: 879 loss: tensor(0.0452)\n",
            "epoch: 880 loss: tensor(0.0442)\n",
            "epoch: 881 loss: tensor(0.0449)\n",
            "epoch: 882 loss: tensor(0.0452)\n",
            "epoch: 883 loss: tensor(0.0453)\n",
            "epoch: 884 loss: tensor(0.0450)\n",
            "epoch: 885 loss: tensor(0.0445)\n",
            "epoch: 886 loss: tensor(0.0448)\n",
            "epoch: 887 loss: tensor(0.0445)\n",
            "epoch: 888 loss: tensor(0.0451)\n",
            "epoch: 889 loss: tensor(0.0443)\n",
            "epoch: 890 loss: tensor(0.0444)\n",
            "epoch: 891 loss: tensor(0.0438)\n",
            "epoch: 892 loss: tensor(0.0447)\n",
            "epoch: 893 loss: tensor(0.0442)\n",
            "epoch: 894 loss: tensor(0.0451)\n",
            "epoch: 895 loss: tensor(0.0443)\n",
            "epoch: 896 loss: tensor(0.0447)\n",
            "epoch: 897 loss: tensor(0.0443)\n",
            "epoch: 898 loss: tensor(0.0452)\n",
            "epoch: 899 loss: tensor(0.0439)\n",
            "epoch: 900 loss: tensor(0.0448)\n",
            "epoch: 901 loss: tensor(0.0440)\n",
            "epoch: 902 loss: tensor(0.0444)\n",
            "epoch: 903 loss: tensor(0.0432)\n",
            "epoch: 904 loss: tensor(0.0438)\n",
            "epoch: 905 loss: tensor(0.0442)\n",
            "epoch: 906 loss: tensor(0.0448)\n",
            "epoch: 907 loss: tensor(0.0436)\n",
            "epoch: 908 loss: tensor(0.0441)\n",
            "epoch: 909 loss: tensor(0.0436)\n",
            "epoch: 910 loss: tensor(0.0455)\n",
            "epoch: 911 loss: tensor(0.0448)\n",
            "epoch: 912 loss: tensor(0.0448)\n",
            "epoch: 913 loss: tensor(0.0454)\n",
            "epoch: 914 loss: tensor(0.0447)\n",
            "epoch: 915 loss: tensor(0.0444)\n",
            "epoch: 916 loss: tensor(0.0446)\n",
            "epoch: 917 loss: tensor(0.0454)\n",
            "epoch: 918 loss: tensor(0.0442)\n",
            "epoch: 919 loss: tensor(0.0451)\n",
            "epoch: 920 loss: tensor(0.0436)\n",
            "epoch: 921 loss: tensor(0.0451)\n",
            "epoch: 922 loss: tensor(0.0447)\n",
            "epoch: 923 loss: tensor(0.0456)\n",
            "epoch: 924 loss: tensor(0.0451)\n",
            "epoch: 925 loss: tensor(0.0449)\n",
            "epoch: 926 loss: tensor(0.0450)\n",
            "epoch: 927 loss: tensor(0.0441)\n",
            "epoch: 928 loss: tensor(0.0451)\n",
            "epoch: 929 loss: tensor(0.0444)\n",
            "epoch: 930 loss: tensor(0.0448)\n",
            "epoch: 931 loss: tensor(0.0441)\n",
            "epoch: 932 loss: tensor(0.0444)\n",
            "epoch: 933 loss: tensor(0.0441)\n",
            "epoch: 934 loss: tensor(0.0449)\n",
            "epoch: 935 loss: tensor(0.0436)\n",
            "epoch: 936 loss: tensor(0.0449)\n",
            "epoch: 937 loss: tensor(0.0440)\n",
            "epoch: 938 loss: tensor(0.0447)\n",
            "epoch: 939 loss: tensor(0.0448)\n",
            "epoch: 940 loss: tensor(0.0446)\n",
            "epoch: 941 loss: tensor(0.0443)\n",
            "epoch: 942 loss: tensor(0.0441)\n",
            "epoch: 943 loss: tensor(0.0444)\n",
            "epoch: 944 loss: tensor(0.0440)\n",
            "epoch: 945 loss: tensor(0.0450)\n",
            "epoch: 946 loss: tensor(0.0444)\n",
            "epoch: 947 loss: tensor(0.0440)\n",
            "epoch: 948 loss: tensor(0.0442)\n",
            "epoch: 949 loss: tensor(0.0443)\n",
            "epoch: 950 loss: tensor(0.0446)\n",
            "epoch: 951 loss: tensor(0.0446)\n",
            "epoch: 952 loss: tensor(0.0442)\n",
            "epoch: 953 loss: tensor(0.0443)\n",
            "epoch: 954 loss: tensor(0.0445)\n",
            "epoch: 955 loss: tensor(0.0440)\n",
            "epoch: 956 loss: tensor(0.0443)\n",
            "epoch: 957 loss: tensor(0.0441)\n",
            "epoch: 958 loss: tensor(0.0443)\n",
            "epoch: 959 loss: tensor(0.0439)\n",
            "epoch: 960 loss: tensor(0.0443)\n",
            "epoch: 961 loss: tensor(0.0445)\n",
            "epoch: 962 loss: tensor(0.0440)\n",
            "epoch: 963 loss: tensor(0.0444)\n",
            "epoch: 964 loss: tensor(0.0442)\n",
            "epoch: 965 loss: tensor(0.0445)\n",
            "epoch: 966 loss: tensor(0.0442)\n",
            "epoch: 967 loss: tensor(0.0452)\n",
            "epoch: 968 loss: tensor(0.0444)\n",
            "epoch: 969 loss: tensor(0.0450)\n",
            "epoch: 970 loss: tensor(0.0448)\n",
            "epoch: 971 loss: tensor(0.0446)\n",
            "epoch: 972 loss: tensor(0.0441)\n",
            "epoch: 973 loss: tensor(0.0449)\n",
            "epoch: 974 loss: tensor(0.0444)\n",
            "epoch: 975 loss: tensor(0.0443)\n",
            "epoch: 976 loss: tensor(0.0445)\n",
            "epoch: 977 loss: tensor(0.0445)\n",
            "epoch: 978 loss: tensor(0.0449)\n",
            "epoch: 979 loss: tensor(0.0446)\n",
            "epoch: 980 loss: tensor(0.0449)\n",
            "epoch: 981 loss: tensor(0.0443)\n",
            "epoch: 982 loss: tensor(0.0447)\n",
            "epoch: 983 loss: tensor(0.0446)\n",
            "epoch: 984 loss: tensor(0.0450)\n",
            "epoch: 985 loss: tensor(0.0444)\n",
            "epoch: 986 loss: tensor(0.0451)\n",
            "epoch: 987 loss: tensor(0.0438)\n",
            "epoch: 988 loss: tensor(0.0444)\n",
            "epoch: 989 loss: tensor(0.0443)\n",
            "epoch: 990 loss: tensor(0.0444)\n",
            "epoch: 991 loss: tensor(0.0442)\n",
            "epoch: 992 loss: tensor(0.0448)\n",
            "epoch: 993 loss: tensor(0.0441)\n",
            "epoch: 994 loss: tensor(0.0440)\n",
            "epoch: 995 loss: tensor(0.0435)\n",
            "epoch: 996 loss: tensor(0.0438)\n",
            "epoch: 997 loss: tensor(0.0441)\n",
            "epoch: 998 loss: tensor(0.0438)\n",
            "epoch: 999 loss: tensor(0.0450)\n",
            "epoch: 1000 loss: tensor(0.0441)\n",
            "Stacked-Autoencoder(SAE) Training Time : 3.0 Minutes. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qeM1jQolOz9l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "49c746a8-bacd-413c-af8b-6b84a5e148d3"
      },
      "source": [
        "epochs = range(1,1001)\n",
        "plt.plot(epochs, closses, 'c', label=' batch size = 500 ') # 'g' = color green\n",
        "plt.title('Batch Normalization- epoch = 1000')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B4h6f0HiOz9p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12534a27-19b3-4489-d8a3-d330a3731d87"
      },
      "source": [
        "sae.eval()\n",
        "with torch.no_grad():\n",
        "  test_loss = 0\n",
        "  s = 0.\n",
        "  for input1,target1 in zip(train_loader,test_loader):\n",
        "      input = Variable(input1)\n",
        "      target = Variable(target1)\n",
        "      if torch.sum(target.data > 0) > 0:\n",
        "          output = sae(input)\n",
        "          target.require_grad = False\n",
        "          output[(target == 0)] = 0\n",
        "          loss = criterion(output, target)\n",
        "          mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "          test_loss += np.sqrt(loss.data*mean_corrector)\n",
        "          s += 1.\n",
        "  print('test_loss: '+str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss: tensor(0.0478)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wa9GF2i7Oz9x",
        "colab": {}
      },
      "source": [
        "from math import sqrt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xAZuTxhJOz9z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5a38307-c6eb-4a01-bfa0-4de18e581133"
      },
      "source": [
        "RMSE = sqrt(0.0478)\n",
        "\n",
        "RMSE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21863211109075448"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WSPyynsbRQ-s",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x2Jy6vYrRQ-1",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}